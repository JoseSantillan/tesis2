{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if not os.path.isdir(\"./libs\"):\n",
    "    os.mkdir(\"./libs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./libs/util_bd.py\n",
    "import mysql.connector\n",
    "import myloginpath\n",
    "import pandas as pd\n",
    "\n",
    "def resultados_query(query):\n",
    "    conf = myloginpath.parse('tesis2')\n",
    "    conn = mysql.connector.connect(**conf, db=\"tesis2\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    resultado = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return resultado\n",
    "\n",
    "def ejecutar_query(query):\n",
    "    conf = myloginpath.parse('tesis2')\n",
    "    conn = mysql.connector.connect(**conf, db=\"tesis2\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    conn.close()\n",
    "\n",
    "def mostrar_resultado_query(query):\n",
    "    conf = myloginpath.parse('tesis2')\n",
    "    conn = mysql.connector.connect(**conf, db=\"tesis2\")\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    display(df)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./libs/util_fasta.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./libs/util_fasta.py\n",
    "import os\n",
    "\n",
    "def generar_fasta(secuencias, archivo, tamanio_por_linea=80):\n",
    "    t_tamanio = tamanio_por_linea\n",
    "    f = open(archivo ,\"w+\")\n",
    "    for transcrito in secuencias:\n",
    "        f.write(\">%s\\n\" % (transcrito[0].strip().upper()))\n",
    "        seq = transcrito[1]\n",
    "        t_partes = [seq[i:i+t_tamanio] for i in range(0, len(seq), t_tamanio)]\n",
    "        for t_parte in t_partes:\n",
    "            f.write(\"%s\\n\" % (t_parte))\n",
    "    f.close()\n",
    "\n",
    "def leer_fasta(archivo, limite = 0):\n",
    "    transcritos = {}\n",
    "    cod_secuencia = \"\"\n",
    "    secuencia = \"\"\n",
    "    f = open(archivo, \"r\")\n",
    "    for linea in f:\n",
    "        if linea.startswith(\">\"):\n",
    "            if secuencia != \"\":\n",
    "                transcritos[cod_secuencia] = secuencia\n",
    "                secuencia = \"\"\n",
    "                limite -= 1\n",
    "                if limite == 0:\n",
    "                    break\n",
    "            cod_secuencia = linea.rstrip(\"\\n\").lstrip(\">\").strip().upper()\n",
    "        else:\n",
    "            secuencia += linea.rstrip(\"\\n\")\n",
    "    if secuencia != \"\":\n",
    "        transcritos[cod_secuencia] = secuencia\n",
    "        secuencia = \"\"\n",
    "    f.close()\n",
    "    return transcritos\n",
    "\n",
    "def leer_fasta_list(archivo, limite = 0):\n",
    "    transcritos = list()\n",
    "    cod_secuencia = \"\"\n",
    "    secuencia = \"\"\n",
    "    f = open(archivo, \"r\")\n",
    "    for linea in f:\n",
    "        if linea.startswith(\">\"):\n",
    "            if secuencia != \"\":\n",
    "                transcritos.append((cod_secuencia, secuencia))\n",
    "                secuencia = \"\"\n",
    "                limite -= 1\n",
    "                if limite == 0:\n",
    "                    break\n",
    "            cod_secuencia = linea.rstrip(\"\\n\").lstrip(\">\").strip().upper()\n",
    "        else:\n",
    "            secuencia += linea.rstrip(\"\\n\")\n",
    "    if secuencia != \"\":\n",
    "        transcritos.append((cod_secuencia, secuencia))\n",
    "        secuencia = \"\"\n",
    "    f.close()\n",
    "    return transcritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./libs/util_caracteristicas.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./libs/util_caracteristicas.py\n",
    "import os\n",
    "import util_fasta\n",
    "from Bio.SeqUtils import GC\n",
    "import csv\n",
    "from sklearn.externals.joblib import dump, load\n",
    "#import random\n",
    "#import string\n",
    "#import shutil\n",
    "\n",
    "def generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat):\n",
    "    _generar_modelo_CPAT_hexamer(archivo_lncRNA, archivo_CDS, carpeta_cpat)\n",
    "    _generar_modelo_CPAT_logit(archivo_lncRNA, archivo_PCT, carpeta_cpat)\n",
    "\n",
    "def _generar_modelo_CPAT_hexamer(archivo_lncRNA, archivo_CDS, carpeta_cpat):\n",
    "    script = \"~/anaconda3/bin/make_hexamer_tab.py\"\n",
    "    fasta_cds = \"'\" + archivo_CDS + \"'\" \n",
    "    fasta_lncRNA = \"'\" + archivo_lncRNA + \"'\"\n",
    "    salida = \"'\" + carpeta_cpat + \"/hexamer.tsv\" + \"'\"\n",
    "    comando = \"{} -c {} -n {} > {}\".format(script, fasta_cds, fasta_lncRNA, salida)\n",
    "    os.system(comando)\n",
    "    \n",
    "def _generar_modelo_CPAT_logit(archivo_lncRNA, archivo_PCT, carpeta_cpat):\n",
    "    script = \"~/anaconda3/bin/make_logitModel.py\"\n",
    "    hexamer = \"'\" + carpeta_cpat + \"/hexamer.tsv\" + \"'\"\n",
    "    fasta_pct = \"'\" + archivo_PCT + \"'\" \n",
    "    fasta_lncRNA = \"'\" + archivo_lncRNA + \"'\"\n",
    "    salida = \"'\" + carpeta_cpat + \"/fold\" + \"'\"\n",
    "    comando = \"{} -x {} -c {} -n {} -o {}\".format(script, hexamer, fasta_pct, fasta_lncRNA, salida)\n",
    "    os.system(comando)\n",
    "    \n",
    "def ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida):\n",
    "    script = \"~/anaconda3/bin/diamond\"\n",
    "    diamond_bd = \"'\" + diamond_db + \"'\"\n",
    "    salida = \"'\" + archivo_salida + \"'\"\n",
    "    comando = \"{} blastx -d {} -q {} -o {} -k 5 --gapopen 11 --gapextend 1 --more-sensitive -f 6 qseqid pident length qframe qstart qend sstart send evalue bitscore\".format(script, diamond_bd, archivo_entrada, salida)\n",
    "    os.system(comando)\n",
    "\n",
    "def ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida):\n",
    "    script = \"~/anaconda3/bin/cpat.py\"\n",
    "    logit = \"'\" + carpeta_cpat + \"/fold.logit.RData\" + \"'\"\n",
    "    hexamer = \"'\" + carpeta_cpat + \"/hexamer.tsv\" + \"'\"\n",
    "    salida = \"'\" + archivo_salida + \"'\"\n",
    "    comando = \"{} -g {} -d {} -x {} -o {}\".format(script, archivo_entrada, logit, hexamer, salida)\n",
    "    os.system(comando)\n",
    "    \n",
    "def generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida):\n",
    "    transcritos = util_fasta.leer_fasta(archivo_entrada)\n",
    "    transcript_dict = {}\n",
    "    for k in transcritos.keys():\n",
    "        transcript_dict[k.strip().upper()] = {\n",
    "            \"length\" : len(transcritos[k]),\n",
    "            \"gc\" : GC(transcritos[k]),\n",
    "            \"orf_length\" : 0,\n",
    "            \"orf_coverage\" : float(0),\n",
    "            \"hexamer_score\" : float(0),\n",
    "            \"fickett_score\" : float(0),\n",
    "            \"identity\" : float(0),\n",
    "            \"align_length\" : float(0),\n",
    "            \"align_perc_len\" : float(0),\n",
    "            \"align_perc_orf\" : float(0)\n",
    "        }\n",
    "    \n",
    "    #adaptado de https://github.com/gbgolding/crema/blob/master/bin/featuresetup_module.py\n",
    "    with open(archivo_cpat, \"r\") as f:\n",
    "        cpat_reader = csv.reader(f, delimiter=(\"\\t\"))\n",
    "        next(cpat_reader, None) # skip header\n",
    "        for row in cpat_reader:\n",
    "            cod_secuencia = row[0]\n",
    "            transcript_dict[cod_secuencia][\"orf_length\"] = float(row[2])\n",
    "            transcript_dict[cod_secuencia][\"orf_coverage\"] = float(row[2])/float(transcript_dict[cod_secuencia][\"length\"])\n",
    "            transcript_dict[cod_secuencia][\"fickett_score\"] = float(row[3])\n",
    "            transcript_dict[cod_secuencia][\"hexamer_score\"] = float(row[4])\n",
    "    \n",
    "    with open(archivo_diamond, \"r\") as f:\n",
    "        tab_reader = csv.reader(f, delimiter=(\"\\t\"))\n",
    "        line_1 = next(tab_reader)\n",
    "        first = line_1[0].upper()\n",
    "        score = [float(line_1[9])]\n",
    "        with_len = [[first, float(line_1[1]), float(line_1[2]), float(line_1[3]), float(line_1[9])]] # name identity length frame score\n",
    "        for row in tab_reader:\n",
    "            if row[0].upper() == first:\n",
    "                score.append(float(row[9]))\n",
    "                with_len.append([row[0].upper(), float(row[1]), float(row[2]), float(row[3]), float(row[9])])\n",
    "            else:\n",
    "                transcript_dict[first][\"identity\"] = float(0)\n",
    "                transcript_dict[first][\"align_length\"] = float(0)\n",
    "                max_value = max(score)\n",
    "                max_index = score.index(max_value)\n",
    "                max_len_ident = with_len[max_index]\n",
    "                if max_len_ident[3] > 0:\n",
    "                    transcript_dict[first][\"identity\"] = float(max_len_ident[1])\n",
    "                    transcript_dict[first][\"align_length\"] = float(max_len_ident[2])\n",
    "                    transcript_dict[first][\"align_perc_len\"] = float(transcript_dict[first][\"align_length\"]/transcript_dict[first][\"length\"])\n",
    "                    transcript_dict[first][\"align_perc_orf\"] = (0 if transcript_dict[first][\"orf_length\"] == 0 else float(transcript_dict[first][\"align_length\"]/transcript_dict[first][\"orf_length\"]))\n",
    "                score = [float(row[9])]\n",
    "                first = row[0].upper()\n",
    "                with_len = [[first, float(row[1]), float(row[2]), float(row[3]), float(row[9])]]\n",
    "        transcript_dict[first][\"identity\"] = float(0)\n",
    "        transcript_dict[first][\"align_length\"] = float(0)\n",
    "        max_value = max(score)\n",
    "        max_index = score.index(max_value)\n",
    "        max_len_ident = with_len[max_index]\n",
    "        if max_len_ident[3] > 0:\n",
    "            transcript_dict[first][\"identity\"] = float(max_len_ident[1])\n",
    "            transcript_dict[first][\"align_length\"] = float(max_len_ident[2])\n",
    "    #fin de c√≥digo adaptado de https://github.com/gbgolding/crema/blob/master/bin/featuresetup_module.py\n",
    "    \n",
    "    dump(transcript_dict, archivo_salida)\n",
    "\n",
    "def generar_features(archivo_entrada, features_base, archivo_cpat, archivo_salida):\n",
    "    transcritos = util_fasta.leer_fasta(archivo_entrada)\n",
    "    features_globales = load(features_base)\n",
    "    transcript_dict = {}\n",
    "    for k in transcritos.keys():\n",
    "        transcript_dict[k.strip().upper()] = {\n",
    "            \"length\" : features_globales[k.strip().upper()][\"length\"],\n",
    "            \"gc\" : features_globales[k.strip().upper()][\"gc\"],\n",
    "            \"orf_length\" : features_globales[k.strip().upper()][\"orf_length\"],\n",
    "            \"orf_coverage\" : features_globales[k.strip().upper()][\"orf_coverage\"],\n",
    "            \"hexamer_score\" : float(0),\n",
    "            \"fickett_score\" : float(0),\n",
    "            \"identity\" : features_globales[k.strip().upper()][\"identity\"],\n",
    "            \"align_length\" : features_globales[k.strip().upper()][\"align_length\"],\n",
    "            \"align_perc_len\" : features_globales[k.strip().upper()][\"align_perc_len\"],\n",
    "            \"align_perc_orf\" : features_globales[k.strip().upper()][\"align_perc_orf\"]\n",
    "        }\n",
    "    \n",
    "    with open(archivo_cpat, \"r\") as f:\n",
    "        cpat_reader = csv.reader(f, delimiter=(\"\\t\"))\n",
    "        next(cpat_reader, None) # skip header\n",
    "        for row in cpat_reader:\n",
    "            cod_secuencia = row[0].strip().upper()\n",
    "            if cod_secuencia in transcript_dict:\n",
    "                transcript_dict[cod_secuencia][\"fickett_score\"] = float(row[3])\n",
    "                transcript_dict[cod_secuencia][\"hexamer_score\"] = float(row[4])\n",
    "                \n",
    "    dump(transcript_dict, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./libs/util_modelo_referencial.py\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import util_caracteristicas, util_fasta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals.joblib import dump, load\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "class GeneradorFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, identificador=None, X_train=None,y_train=None):\n",
    "        #generar todos los features\n",
    "        self.identificador = identificador\n",
    "        if X_train is None or y_train is None:\n",
    "            return\n",
    "        codigos_lncRNA = {}\n",
    "        codigos_PCT = {}\n",
    "        for i in range(len(X_train)):\n",
    "            if y_train[i] == 0:\n",
    "                codigos_PCT[X_train[i][0]] = X_train[i][1]\n",
    "            else:\n",
    "                codigos_lncRNA[X_train[i][0]] = X_train[i][1]\n",
    "        util_caracteristicas.generar_modelo_CPAT(identificador, codigos_lncRNA, codigos_PCT)\n",
    "        util_caracteristicas.generar_caracteristicas(identificador, {**codigos_lncRNA, **codigos_PCT})\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        #ejecutar cpat para el conjunto de datos\n",
    "        identificador = self.identificador\n",
    "        self._id_cpat = identificador + \"_fold_\" + hashlib.sha224(''.join([x[0] for x in X]).encode()).hexdigest()#str(hash(frozenset({x[0]:1 for x in X})))\n",
    "        id_cpat = self._id_cpat\n",
    "        if util_caracteristicas.existe_modelo_cpat(id_cpat):\n",
    "            return self\n",
    "        codigos_lncRNA = {}\n",
    "        codigos_PCT = {}\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 0:\n",
    "                codigos_PCT[X[i][0]] = X[i][1]\n",
    "            else:\n",
    "                codigos_lncRNA[X[i][0]] = X[i][1]\n",
    "        util_caracteristicas.generar_modelo_CPAT(id_cpat, codigos_lncRNA, codigos_PCT)\n",
    "        util_caracteristicas.generar_caracteristicas_cpat(identificador, {**codigos_lncRNA, **codigos_PCT})\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        #obtener caracteristicas\n",
    "        identificador = self.identificador\n",
    "        id_cpat = self._id_cpat\n",
    "        codigos = {codigo[0]:codigo[1] for codigo in X}\n",
    "        util_caracteristicas.generar_caracteristicas_cpat(id_cpat, codigos)\n",
    "        dict_features = util_caracteristicas.obtener_caracteristicas(identificador, id_cpat, codigos)\n",
    "\n",
    "        return [list(x.values()) for x in dict_features.values()]\n",
    "\n",
    "def crear_modelo_referencial(identificador, tuned_parameters, scores, n_jobs, cv):\n",
    "    if not os.path.isdir(\"./modelos_referenciales\"):\n",
    "        os.mkdir(\"./modelos_referenciales\")\n",
    "    \n",
    "    codigos_lncRNA = util_fasta.leer_fasta(\"./data/\" + identificador + \".lncRNA.fasta\")\n",
    "    codigos_PCT = util_fasta.leer_fasta(\"./data/\" + identificador + \".PCT.fasta\")\n",
    "    \n",
    "    X = list(codigos_lncRNA.items()) + list(codigos_PCT.items())\n",
    "    y = ([1] * len(codigos_lncRNA)) + ([0] * len(codigos_PCT))\n",
    "    X_train, y_train = X, y #shuffle(X, y, random_state=0)\n",
    "    svm_pipeline = Pipeline(steps=[('features', GeneradorFeatures(identificador, X_train, y_train)), ('svc', SVC())])\n",
    "    \n",
    "    for score in scores:\n",
    "        clf = GridSearchCV(svm_pipeline, tuned_parameters, cv=cv, scoring=score, n_jobs=n_jobs, refit=\"accuracy\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        resultado = {\n",
    "            \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "            \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "            \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "        }\n",
    "        dump(resultado, './modelos_referenciales/resultado_{}.bin'.format(identificador))\n",
    "        dump(clf.best_estimator_, './modelos_referenciales/modelo_{}.plk'.format(identificador), compress = 1)\n",
    "        \n",
    "        #means = clf.cv_results_['mean_test_accuracy']\n",
    "        #stds = clf.cv_results_['std_test_accuracy']\n",
    "        #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        #          % (mean, std * 2, params))\n",
    "        #print()\n",
    "\n",
    "        #print(\"Detailed classification report:\")\n",
    "        #print()\n",
    "        #print(\"The model is trained on the full development set.\")\n",
    "        #print(\"The scores are computed on the full evaluation set.\")\n",
    "        #print()\n",
    "        #y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        #print(classification_report(y_true, y_pred))\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./libs/util_modelo_final.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
