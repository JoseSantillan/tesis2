{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "start = time.time()\n",
    "cantidad_especies = 30\n",
    "cantidad_especies = 3\n",
    "cantidad_transcritos = 4208\n",
    "#cantidad_transcritos = 400\n",
    "n_jobs = 4\n",
    "verbose = 0\n",
    "carpeta_base = \"./real\"\n",
    "carpeta_base = \"./prueba\"\n",
    "if os.path.isdir(carpeta_base):\n",
    "    shutil.rmtree(carpeta_base)\n",
    "os.mkdir(carpeta_base)\n",
    "carpeta_data_base = carpeta_base + \"/data\"\n",
    "carpeta_fold_base = carpeta_base + \"/folds\"\n",
    "carpeta_modelo_base = carpeta_base + \"/modelos_referenciales\"\n",
    "tuned_parameters = [{'svc__kernel': ['rbf'], 'svc__gamma': [1e-3], 'svc__C': [0.1,0.5,0.9,2]}]\n",
    "score = ['accuracy','precision','recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 ms, sys: 252 µs, total: 2.44 ms\n",
      "Wall time: 2.97 ms\n",
      "CPU times: user 6.29 ms, sys: 3.44 ms, total: 9.73 ms\n",
      "Wall time: 9.19 s\n",
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Generación de archivos fasta para las 30 especies\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_bd, util_fasta\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.externals.joblib import Parallel, delayed, dump\n",
    "\n",
    "def carpeta_data():\n",
    "    return carpeta_data_base\n",
    "\n",
    "def carpeta_fold():\n",
    "    return carpeta_fold_base\n",
    "\n",
    "def carpeta_modelo():\n",
    "    return carpeta_modelo_base\n",
    "\n",
    "def obtener_especies():\n",
    "    query = \"SELECT * FROM (SELECT CONVERT(@row_number:=@row_number + 1, UNSIGNED) AS orden, m.id_especie, m.especie FROM especies_seleccionadas s JOIN maestra_especies m ON s.especie = m.especie, (SELECT @row_number:=0) AS rn ORDER BY m.id_especie) a ORDER BY 1 LIMIT \" + str(cantidad_especies)\n",
    "    return util_bd.resultados_query(query)\n",
    "        \n",
    "def generar_fasta_especie(row_especie):\n",
    "    os.mkdir(carpeta_data() + \"/clase_\" + str(row_especie[0]))\n",
    "    # lncRNA\n",
    "    query = \"SELECT cod_secuencia, secuencia FROM secuencias WHERE flg_pct = 0 AND flg_seleccionado = 1 AND id_especie = \" + str(row_especie[1]) + \" ORDER BY cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data() + \"/clase_\" + str(row_especie[0]) + \"/lncRNA.fa\")\n",
    "    # PCT\n",
    "    query = \"SELECT cod_secuencia, secuencia FROM secuencias WHERE flg_pct = 1 AND flg_seleccionado = 1 AND id_especie = \" + str(row_especie[1]) + \" ORDER BY cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data() + \"/clase_\" + str(row_especie[0]) + \"/PCT.fa\")\n",
    "    # CDS\n",
    "    query = \"SELECT f.cod_secuencia, cds.coding FROM secuencias_CDS cds JOIN secuencias_features f ON cds.id_especie = f.id_especie AND cds.cod_secuencia = f.cod_secuencia WHERE f.flg_pct = 1 AND f.flg_seleccionado = 1 AND f.id_especie = \" + str(row_especie[1]) + \" ORDER BY f.cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data() + \"/clase_\" + str(row_especie[0]) + \"/CDS.fa\")\n",
    "\n",
    "if os.path.isdir(carpeta_data()):\n",
    "    shutil.rmtree(carpeta_data())\n",
    "os.mkdir(carpeta_data())\n",
    "\n",
    "%time dump(obtener_especies(), carpeta_data() + \"/info_clases.bin\")\n",
    "%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(generar_fasta_especie)(row_especie) for row_especie in obtener_especies())\n",
    "\n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 ms, sys: 0 ns, total: 1.42 ms\n",
      "Wall time: 1.43 ms\n",
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Construir llave de folds\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_fasta\n",
    "import hashlib\n",
    "from sklearn.externals.joblib import dump, load\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_fasta) \n",
    "\n",
    "def folder_clase(num_clase):\n",
    "    return carpeta_data() + \"/clase_\" + str(num_clase)\n",
    "\n",
    "def archivo_clase(num_clase, tipo):\n",
    "    return folder_clase(num_clase) + \"/\" + tipo + \".fa\"\n",
    "\n",
    "def obtener_num_clases():\n",
    "    num_clases = 0\n",
    "    if not os.path.isfile(carpeta_data() + \"/num_clases.bin\"):\n",
    "        while os.path.isdir(folder_clase(num_clases + 1)):\n",
    "            num_clases = num_clases + 1\n",
    "        dump(num_clases, carpeta_data() + \"/num_clases.bin\")\n",
    "    num_clases = load(carpeta_data() + \"/num_clases.bin\")\n",
    "    return num_clases\n",
    "\n",
    "def iterador_clases():\n",
    "    return range(1, obtener_num_clases() + 1)\n",
    "\n",
    "def obtener_primera_secuencia(num_clase):\n",
    "    secuencias = util_fasta.leer_fasta(archivo_clase(num_clase, \"lncRNA\"), 1)\n",
    "    return list(secuencias.keys())[0]\n",
    "\n",
    "def obtener_todas_las_secuencias():\n",
    "    return {num_clase : obtener_primera_secuencia(num_clase) for num_clase in iterador_clases()}\n",
    "\n",
    "def generar_llaves_clases():\n",
    "    secuencias = obtener_todas_las_secuencias()\n",
    "    llaves = {num_clase : \"\" for num_clase in secuencias.keys()}\n",
    "    llaves[0] = \"\" #llave cero corresponde a todo el universo\n",
    "    for i_clase in iterador_clases():\n",
    "        llaves[0] += secuencias[i_clase]\n",
    "        for j_clase in iterador_clases():\n",
    "            if (i_clase != j_clase):\n",
    "                llaves[j_clase] += secuencias[i_clase]\n",
    "    llaves[0] = hashlib.sha224(llaves[0].encode()).hexdigest()\n",
    "    for i_clase in iterador_clases():\n",
    "        llaves[i_clase] = hashlib.sha224(llaves[i_clase].encode()).hexdigest()\n",
    "    dump(llaves, carpeta_data() + \"/llaves_clases.bin\")\n",
    "\n",
    "def obtener_llaves_clases():\n",
    "    return load(carpeta_data() + \"/llaves_clases.bin\")\n",
    "\n",
    "%time generar_llaves_clases()\n",
    "\n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 0 ns, total: 12 ms\n",
      "Wall time: 536 ms\n",
      "CPU times: user 11.9 ms, sys: 443 µs, total: 12.3 ms\n",
      "Wall time: 1.16 s\n",
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Armando folds (archivos fasta)\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.externals.joblib import Parallel, delayed, load\n",
    "\n",
    "def cargar_llaves_clases():\n",
    "    return load(carpeta_data() + \"/llaves_clases.bin\")\n",
    "\n",
    "def carpeta_fold_clase(llave):\n",
    "    return carpeta_fold() + \"/fold_clase_\" + str(llave)\n",
    "\n",
    "def archivo_fold_clase(llave, tipoTrainTest, tipoRNA):\n",
    "    return carpeta_fold_clase(llave) + \"/\" + tipoTrainTest + \"/\" + tipoRNA + \".fa\"\n",
    "\n",
    "def armar_fold_final(tipo):\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    if not os.path.isdir(carpeta_fold_clase(llave)):\n",
    "        os.mkdir(carpeta_fold_clase(llave))\n",
    "    if not os.path.isdir(carpeta_fold_clase(llave) + \"/train\"):\n",
    "        os.mkdir(carpeta_fold_clase(llave) + \"/train\")\n",
    "    with open(archivo_fold_clase(llave, \"train\", tipo), \"w+\") as outfile:\n",
    "        for num_clase in iterador_clases():\n",
    "            with open(archivo_clase(num_clase, tipo), \"r\") as infile:\n",
    "                for inline in infile:\n",
    "                    outfile.write(inline)\n",
    "    \n",
    "def armar_fold_clase(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    os.mkdir(carpeta_fold_clase(llave))\n",
    "    os.mkdir(carpeta_fold_clase(llave) + \"/train\")\n",
    "    for tipo in [\"lncRNA\", \"PCT\", \"CDS\"]:\n",
    "        with open(archivo_fold_clase(llave, \"train\", tipo), \"w+\") as outfile:\n",
    "            for j_num_clase in iterador_clases():\n",
    "                if num_clase != j_num_clase:\n",
    "                    with open(archivo_clase(j_num_clase, tipo)) as infile:\n",
    "                        for inline in infile:\n",
    "                            outfile.write(inline)\n",
    "    os.mkdir(carpeta_fold_clase(llave) + \"/test\")\n",
    "    for tipo in [\"lncRNA\", \"PCT\"]:\n",
    "        with open(archivo_fold_clase(llave, \"test\", tipo), \"w+\") as outfile:\n",
    "            with open(archivo_clase(num_clase, tipo)) as infile:\n",
    "                for inline in infile:\n",
    "                    outfile.write(inline)\n",
    "\n",
    "if os.path.isdir(carpeta_fold()):\n",
    "    shutil.rmtree(carpeta_fold())\n",
    "os.mkdir(carpeta_fold())\n",
    "\n",
    "%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(armar_fold_final)(tipo) for tipo in [\"lncRNA\", \"PCT\", \"CDS\"])\n",
    "%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(armar_fold_clase)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.85 ms, sys: 4.21 ms, total: 10.1 ms\n",
      "Wall time: 44 s\n",
      "CPU times: user 13.5 ms, sys: 0 ns, total: 13.5 ms\n",
      "Wall time: 55.5 s\n",
      "CPU times: user 0 ns, sys: 2.6 ms, total: 2.6 ms\n",
      "Wall time: 2.18 ms\n",
      "CPU times: user 7.22 ms, sys: 0 ns, total: 7.22 ms\n",
      "Wall time: 8.74 ms\n",
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Generando modelos CPAT de los folds\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_caracteristicas\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_caracteristicas)\n",
    "\n",
    "def carpeta_fold_cpat(llave):\n",
    "    return carpeta_fold_clase(llave) + \"/cpat\"\n",
    "\n",
    "def generar_cpat_fold(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    archivo_CDS = archivo_fold_clase(llave, \"train\", \"CDS\")\n",
    "    carpeta_cpat = carpeta_fold_cpat(llave)\n",
    "    if not os.path.isdir(carpeta_cpat):\n",
    "        os.mkdir(carpeta_cpat)\n",
    "    util_caracteristicas.generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat)\n",
    "    \n",
    "def generar_cpat_final():\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    archivo_CDS = archivo_fold_clase(llave, \"train\", \"CDS\")\n",
    "    carpeta_cpat = carpeta_fold_cpat(llave)\n",
    "    if not os.path.isdir(carpeta_cpat):\n",
    "        os.mkdir(carpeta_cpat)\n",
    "    util_caracteristicas.generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat)\n",
    "\n",
    "def limpieza_archivos_CDS(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    os.remove(archivo_fold_clase(llave, \"train\", \"CDS\"))\n",
    "\n",
    "%time generar_cpat_final()\n",
    "%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(generar_cpat_fold)(num_clase) for num_clase in iterador_clases())\n",
    "%time limpieza_archivos_CDS(0)\n",
    "%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(limpieza_archivos_CDS)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 ms, sys: 24.4 ms, total: 27.6 ms\n",
      "Wall time: 4min 21s\n",
      "CPU times: user 12.2 ms, sys: 486 µs, total: 12.7 ms\n",
      "Wall time: 46.2 s\n",
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Ejecutar cpat y diamond sobre los folds\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_caracteristicas\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_caracteristicas)\n",
    "\n",
    "def ejecutar_cpat_fold(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    carpeta_cpat = carpeta_fold_cpat(llave)\n",
    "    util_caracteristicas.ejecutar_cpat(archivo_lncRNA, carpeta_cpat, archivo_lncRNA.replace(\".fa\", \".cpat\"))\n",
    "    os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "    os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".r\")\n",
    "    util_caracteristicas.ejecutar_cpat(archivo_PCT, carpeta_cpat, archivo_PCT.replace(\".fa\", \".cpat\"))\n",
    "    os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "    os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".r\")\n",
    "\n",
    "def ejecutar_cpat_diamond_final():\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    diamond_db = \"./Diamond_BD/uniprot-viridiplantae-reviewed.dmnd\"\n",
    "    carpeta_cpat = carpeta_fold_cpat(llave)\n",
    "    util_caracteristicas.ejecutar_diamond(archivo_lncRNA, diamond_db, archivo_lncRNA.replace(\".fa\", \".dmnd\"))\n",
    "    util_caracteristicas.ejecutar_diamond(archivo_PCT, diamond_db, archivo_PCT.replace(\".fa\", \".dmnd\"))\n",
    "    util_caracteristicas.ejecutar_cpat(archivo_lncRNA, carpeta_cpat, archivo_lncRNA.replace(\".fa\", \".cpat\"))\n",
    "    os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "    os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".r\")\n",
    "    util_caracteristicas.ejecutar_cpat(archivo_PCT, carpeta_cpat, archivo_PCT.replace(\".fa\", \".cpat\"))\n",
    "    os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "    os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".r\")\n",
    "\n",
    "%time ejecutar_cpat_diamond_final()\n",
    "%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(ejecutar_cpat_fold)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 36.3 ms, total: 2.56 s\n",
      "Wall time: 2.56 s\n",
      "CPU times: user 18.1 ms, sys: 11.9 ms, total: 30 ms\n",
      "Wall time: 6.21 s\n",
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Generar archivo de features por cada fold\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_caracteristicas\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_caracteristicas)\n",
    "\n",
    "def archivo_features_clase(llave, tipoTrainTest, tipoRNA):\n",
    "    return archivo_fold_clase(llave, tipoTrainTest, tipoRNA).replace(\".fa\", \".ft\")\n",
    "\n",
    "def generar_features_fold(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    features_base_lncRNA = archivo_features_clase(obtener_llaves_clases()[0], \"train\", \"lncRNA\")\n",
    "    features_base_PCT = archivo_features_clase(obtener_llaves_clases()[0], \"train\", \"PCT\")\n",
    "    for tipo in [\"train\", \"test\"]:\n",
    "        archivo_lncRNA = archivo_fold_clase(llave, tipo, \"lncRNA\")\n",
    "        archivo_PCT = archivo_fold_clase(llave, tipo, \"PCT\")\n",
    "        archivo_cpat_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\").replace(\".fa\", \".cpat\")\n",
    "        archivo_cpat_PCT = archivo_fold_clase(llave, \"train\", \"PCT\").replace(\".fa\", \".cpat\")\n",
    "        salida_lncRNA = archivo_features_clase(llave, tipo, \"lncRNA\")\n",
    "        salida_PCT = archivo_features_clase(llave, tipo, \"PCT\")\n",
    "        util_caracteristicas.generar_features(archivo_lncRNA, features_base_lncRNA, archivo_cpat_lncRNA, salida_lncRNA)\n",
    "        util_caracteristicas.generar_features(archivo_PCT, features_base_PCT, archivo_cpat_PCT, salida_PCT)\n",
    "    \n",
    "def generar_features_final():\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    salida_lncRNA = archivo_features_clase(llave, \"train\", \"lncRNA\")\n",
    "    salida_PCT = archivo_features_clase(llave, \"train\", \"PCT\")\n",
    "    util_caracteristicas.generar_features_base(archivo_lncRNA, archivo_lncRNA.replace(\".fa\", \".cpat\"), archivo_lncRNA.replace(\".fa\", \".dmnd\"), salida_lncRNA)\n",
    "    util_caracteristicas.generar_features_base(archivo_PCT, archivo_PCT.replace(\".fa\", \".cpat\"), archivo_PCT.replace(\".fa\", \".dmnd\"), salida_PCT)\n",
    "\n",
    "%time generar_features_final()\n",
    "%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(generar_features_fold)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 932 ms, total: 1min 43s\n",
      "Wall time: 8min 23s\n",
      "Proceso finalizado\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([51.74953993, 72.13948337, 75.79723454, 84.35999974]),\n",
       " 'std_fit_time': array([1.72237565, 6.48931428, 8.7191827 , 1.01873492]),\n",
       " 'mean_score_time': array([22.81546839, 20.0339601 , 18.96074462, 17.98088479]),\n",
       " 'std_score_time': array([0.37246045, 0.08026949, 0.85122046, 0.13055916]),\n",
       " 'param_svc__C': masked_array(data=[0.1, 0.5, 0.9, 2],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svc__gamma': masked_array(data=[0.001, 0.001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svc__kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'svc__C': 0.1, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 0.5, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 0.9, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'},\n",
       "  {'svc__C': 2, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}],\n",
       " 'split0_test_accuracy': array([0.47884981, 0.53006179, 0.52982414, 0.53659696]),\n",
       " 'split1_test_accuracy': array([0.80739068, 0.85396863, 0.85539449, 0.85468156]),\n",
       " 'split2_test_accuracy': array([0.87583175, 0.90933935, 0.91230989, 0.90886407]),\n",
       " 'mean_test_accuracy': array([0.72069075, 0.76445659, 0.76584284, 0.7667142 ]),\n",
       " 'std_test_accuracy': array([0.17327497, 0.16727656, 0.16850017, 0.16421407]),\n",
       " 'rank_test_accuracy': array([4, 3, 2, 1], dtype=int32),\n",
       " 'split0_train_accuracy': array([0.89418964, 0.92585551, 0.94047053, 0.95057034]),\n",
       " 'split1_train_accuracy': array([0.88486217, 0.9090423 , 0.91599335, 0.92591492]),\n",
       " 'split2_train_accuracy': array([0.86335551, 0.89080323, 0.90369534, 0.91480513]),\n",
       " 'mean_train_accuracy': array([0.88080244, 0.90856702, 0.92005307, 0.93043013]),\n",
       " 'std_train_accuracy': array([0.01291115, 0.01431398, 0.01528539, 0.01494608]),\n",
       " 'split0_test_precision': array([0.33639706, 0.60193392, 0.59572845, 0.60461957]),\n",
       " 'split1_test_precision': array([0.89375951, 0.87024609, 0.86097031, 0.85375681]),\n",
       " 'split2_test_precision': array([0.96887044, 0.94659061, 0.93990872, 0.92809157]),\n",
       " 'mean_test_precision': array([0.733009  , 0.80625687, 0.79886916, 0.79548931]),\n",
       " 'std_test_precision': array([0.2821184 , 0.14780172, 0.14721284, 0.138335  ]),\n",
       " 'rank_test_precision': array([4, 1, 2, 3], dtype=int32),\n",
       " 'split0_train_precision': array([0.94572081, 0.93274571, 0.93326321, 0.93576189]),\n",
       " 'split1_train_precision': array([0.88706979, 0.87651755, 0.8766136 , 0.88120813]),\n",
       " 'split2_train_precision': array([0.87238188, 0.86286408, 0.86630728, 0.87075191]),\n",
       " 'mean_train_precision': array([0.90172416, 0.89070912, 0.89206136, 0.89590731]),\n",
       " 'std_train_precision': array([0.03168294, 0.03024248, 0.02943636, 0.02850291]),\n",
       " 'split0_test_recall': array([0.04348859, 0.17751901, 0.18559886, 0.2115019 ]),\n",
       " 'split1_test_recall': array([0.69771863, 0.83198669, 0.8476711 , 0.85598859]),\n",
       " 'split2_test_recall': array([0.77661597, 0.86763308, 0.88094106, 0.88640684]),\n",
       " 'mean_test_recall': array([0.50594106, 0.62571293, 0.63807034, 0.65129911]),\n",
       " 'std_test_recall': array([0.32858577, 0.3172549 , 0.32023383, 0.31123143]),\n",
       " 'rank_test_recall': array([4, 3, 2, 1], dtype=int32),\n",
       " 'split0_train_recall': array([0.83638308, 0.91789449, 0.94878802, 0.96756179]),\n",
       " 'split1_train_recall': array([0.88201046, 0.95223384, 0.96827471, 0.98455323]),\n",
       " 'split2_train_recall': array([0.85123574, 0.92930133, 0.95472909, 0.97421578]),\n",
       " 'mean_train_recall': array([0.85654309, 0.93314322, 0.95726394, 0.9754436 ]),\n",
       " 'std_train_recall': array([0.01900159, 0.01427977, 0.00815483, 0.00699085])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'svc__C': 2, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7667141951837769,\n",
       " 'precision': 0.7954893148981087,\n",
       " 'recall': 0.6512991128010139}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generar modelo final\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV\n",
    "from sklearn.externals.joblib import dump, load\n",
    "import hashlib\n",
    "import util_fasta\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_fasta)\n",
    "\n",
    "def obtener_data_entrenamiento():\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    codigos_lncRNA = util_fasta.leer_fasta_list(archivo_fold_clase(llave, \"train\", \"lncRNA\"))\n",
    "    codigos_PCT = util_fasta.leer_fasta_list(archivo_fold_clase(llave, \"train\", \"PCT\"))\n",
    "    \n",
    "    y = ([1] * len(codigos_lncRNA)) + ([0] * len(codigos_PCT))\n",
    "    groups = list()\n",
    "    for _ in range(2):\n",
    "        for num_clase in iterador_clases():\n",
    "            groups += ([num_clase] * (cantidad_transcritos))\n",
    "    return codigos_lncRNA + codigos_PCT, y, groups\n",
    "\n",
    "class GeneradorFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cantidad_transcritos=None, num_clases=None):\n",
    "        if cantidad_transcritos is None:\n",
    "            return\n",
    "        self.cantidad_transcritos = cantidad_transcritos\n",
    "        self.num_clases = num_clases\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self._llave_fold = self.obtener_llave_fold(X)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self.obtener_features_pre_calculados(X)\n",
    "    \n",
    "    def obtener_llave_fold(self, X):\n",
    "        cod_secuencias = \"\"\n",
    "        cod_secuencias2 = \"\"\n",
    "        num_transcritos = len(X)\n",
    "        num_transcritos_por_grupo = self.cantidad_transcritos\n",
    "        for i in range(num_transcritos//(num_transcritos_por_grupo*2)):\n",
    "            cod_secuencias += X[i * num_transcritos_por_grupo][0]\n",
    "            cod_secuencias2 += X[i * num_transcritos_por_grupo][0] + \"*****\"\n",
    "        llave = hashlib.sha224(cod_secuencias.encode()).hexdigest()\n",
    "        return llave\n",
    "    \n",
    "    def obtener_features_pre_calculados(self, X):\n",
    "        llave = self._llave_fold\n",
    "        tipo = \"train\"\n",
    "        if os.path.isfile(archivo_fold_clase(llave, \"test\", \"lncRNA\")):\n",
    "            secuencias = util_fasta.leer_fasta(archivo_fold_clase(llave, \"test\", \"lncRNA\"), 1)\n",
    "            if list(secuencias.keys())[0] == X[0][0]:\n",
    "                tipo = \"test\"\n",
    "        features = list(load(archivo_features_clase(llave, tipo, \"lncRNA\")).values())\n",
    "        features += list(load(archivo_features_clase(llave, tipo, \"PCT\")).values())\n",
    "        #[list(x.values()) for x in dict_features.values()]\n",
    "        return [list(x.values()) for x in features]\n",
    "\n",
    "def generar_modelo_final(tuned_parameters):\n",
    "    X_train, y_train, groups = obtener_data_entrenamiento()\n",
    "    svm_pipeline = Pipeline(steps=[('features', GeneradorFeatures(cantidad_transcritos, obtener_num_clases())), ('svc', SVC())])\n",
    "    logo = LeaveOneGroupOut()\n",
    "    clf = GridSearchCV(svm_pipeline, tuned_parameters, cv=logo, scoring=score, n_jobs=n_jobs, refit=\"accuracy\", return_train_score = True)\n",
    "    clf.fit(X_train, y_train, groups) #requerido por LeaveOneGroupOut\n",
    "    resultado = {\n",
    "        \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "        \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "        \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "    }\n",
    "    dump(resultado, carpeta_modelo() + \"/resultado.bin\")\n",
    "    dump(clf.best_params_, carpeta_modelo() + \"/params.bin\")\n",
    "    dump(clf.cv_results_, carpeta_modelo() + \"/cv_results.bin\")\n",
    "    dump(clf.best_estimator_, carpeta_modelo() + \"/modelo.plk\")\n",
    "\n",
    "def limpieza_archivos_finales_fasta_ruta(llave):\n",
    "    for tipo in [\"train\", \"test\"]:\n",
    "        for tipoRNA in [\"lncRNA\", \"PCT\"]:\n",
    "            if os.path.isfile(archivo_fold_clase(llave, tipo, tipoRNA)):\n",
    "                os.remove(archivo_fold_clase(llave, tipo, tipoRNA))\n",
    "            if os.path.isfile(archivo_fold_clase(llave, tipo, tipoRNA).replace(\".fa\", \".cpat\")):\n",
    "                os.remove(archivo_fold_clase(llave, tipo, tipoRNA).replace(\".fa\", \".cpat\"))\n",
    "    \n",
    "def limpieza_archivos_finales_fasta(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    limpieza_archivos_finales_fasta_ruta(llave)\n",
    "    \n",
    "if os.path.isdir(carpeta_modelo()):\n",
    "    shutil.rmtree(carpeta_modelo())\n",
    "os.mkdir(carpeta_modelo())\n",
    "\n",
    "%time generar_modelo_final(tuned_parameters)\n",
    "#%time limpieza_archivos_finales_fasta(0)\n",
    "#%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(limpieza_archivos_finales_fasta)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")\n",
    "\n",
    "display(load(carpeta_modelo() + \"/cv_results.bin\"))\n",
    "display(load(carpeta_modelo() + \"/params.bin\"))\n",
    "display(load(carpeta_modelo() + \"/resultado.bin\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
