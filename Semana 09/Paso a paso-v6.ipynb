{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "start = time.time()\n",
    "cantidad_especies = 30\n",
    "cantidad_transcritos = 4208\n",
    "n_jobs = 4\n",
    "verbose = 0\n",
    "carpeta_base = \"./real\"\n",
    "carpeta_data_base = carpeta_base + \"/data\"\n",
    "carpeta_fold_base = carpeta_base + \"/folds\"\n",
    "carpeta_modelo_base = carpeta_base + \"/modelos_referenciales\"\n",
    "tuned_parameters = [{'svc__kernel': ['rbf'], 'svc__gamma': [1e-3], 'svc__C': [0.1,0.5,0.9,2]}]\n",
    "score = ['accuracy','precision','recall']\n",
    "\n",
    "#cantidad_especies = 3\n",
    "#cantidad_transcritos = 400\n",
    "#carpeta_base = \"./prueba\"\n",
    "verbose = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if os.path.isdir(carpeta_base):\n",
    "#    shutil.rmtree(carpeta_base)\n",
    "#os.mkdir(carpeta_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Generaci√≥n de archivos fasta para las 30 especies\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_bd, util_fasta\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.externals.joblib import Parallel, delayed, dump\n",
    "\n",
    "def carpeta_data():\n",
    "    return carpeta_data_base\n",
    "\n",
    "def carpeta_fold():\n",
    "    return carpeta_fold_base\n",
    "\n",
    "def carpeta_modelo():\n",
    "    return carpeta_modelo_base\n",
    "\n",
    "def obtener_especies():\n",
    "    query = \"SELECT * FROM (SELECT CONVERT(@row_number:=@row_number + 1, UNSIGNED) AS orden, m.id_especie, m.especie FROM especies_seleccionadas s JOIN maestra_especies m ON s.especie = m.especie, (SELECT @row_number:=0) AS rn ORDER BY m.id_especie) a ORDER BY 1 LIMIT \" + str(cantidad_especies)\n",
    "    return util_bd.resultados_query(query)\n",
    "        \n",
    "def generar_fasta_especie(row_especie):\n",
    "    os.mkdir(carpeta_data() + \"/clase_\" + str(row_especie[0]))\n",
    "    # lncRNA\n",
    "    query = \"SELECT cod_secuencia, secuencia FROM secuencias WHERE flg_pct = 0 AND flg_seleccionado = 1 AND id_especie = \" + str(row_especie[1]) + \" ORDER BY cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data() + \"/clase_\" + str(row_especie[0]) + \"/lncRNA.fa\")\n",
    "    # PCT\n",
    "    query = \"SELECT cod_secuencia, secuencia FROM secuencias WHERE flg_pct = 1 AND flg_seleccionado = 1 AND id_especie = \" + str(row_especie[1]) + \" ORDER BY cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data() + \"/clase_\" + str(row_especie[0]) + \"/PCT.fa\")\n",
    "    # CDS\n",
    "    query = \"SELECT f.cod_secuencia, cds.coding FROM secuencias_CDS cds JOIN secuencias_features f ON cds.id_especie = f.id_especie AND cds.cod_secuencia = f.cod_secuencia WHERE f.flg_pct = 1 AND f.flg_seleccionado = 1 AND f.id_especie = \" + str(row_especie[1]) + \" ORDER BY f.cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data() + \"/clase_\" + str(row_especie[0]) + \"/CDS.fa\")\n",
    "\n",
    "#if os.path.isdir(carpeta_data()):\n",
    "#    shutil.rmtree(carpeta_data())\n",
    "#os.mkdir(carpeta_data())\n",
    "\n",
    "#%time dump(obtener_especies(), carpeta_data() + \"/info_clases.bin\")\n",
    "#%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(generar_fasta_especie)(row_especie) for row_especie in #obtener_especies())\n",
    "\n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Construir llave de folds\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_fasta\n",
    "import hashlib\n",
    "from sklearn.externals.joblib import dump, load\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_fasta) \n",
    "\n",
    "def folder_clase(num_clase):\n",
    "    return carpeta_data() + \"/clase_\" + str(num_clase)\n",
    "\n",
    "def archivo_clase(num_clase, tipo):\n",
    "    return folder_clase(num_clase) + \"/\" + tipo + \".fa\"\n",
    "\n",
    "def obtener_num_clases():\n",
    "    num_clases = 0\n",
    "    if not os.path.isfile(carpeta_data() + \"/num_clases.bin\"):\n",
    "        while os.path.isdir(folder_clase(num_clases + 1)):\n",
    "            num_clases = num_clases + 1\n",
    "        dump(num_clases, carpeta_data() + \"/num_clases.bin\")\n",
    "    num_clases = load(carpeta_data() + \"/num_clases.bin\")\n",
    "    return num_clases\n",
    "\n",
    "def iterador_clases():\n",
    "    return range(1, obtener_num_clases() + 1)\n",
    "\n",
    "def obtener_primera_secuencia(num_clase):\n",
    "    secuencias = util_fasta.leer_fasta(archivo_clase(num_clase, \"lncRNA\"), 1)\n",
    "    return list(secuencias.keys())[0]\n",
    "\n",
    "def obtener_todas_las_secuencias():\n",
    "    return {num_clase : obtener_primera_secuencia(num_clase) for num_clase in iterador_clases()}\n",
    "\n",
    "def generar_llaves_clases():\n",
    "    secuencias = obtener_todas_las_secuencias()\n",
    "    llaves = {num_clase : \"\" for num_clase in secuencias.keys()}\n",
    "    llaves[0] = \"\" #llave cero corresponde a todo el universo\n",
    "    for i_clase in iterador_clases():\n",
    "        llaves[0] += secuencias[i_clase]\n",
    "        for j_clase in iterador_clases():\n",
    "            if (i_clase != j_clase):\n",
    "                llaves[j_clase] += secuencias[i_clase]\n",
    "    llaves[0] = hashlib.sha224(llaves[0].encode()).hexdigest()\n",
    "    for i_clase in iterador_clases():\n",
    "        llaves[i_clase] = hashlib.sha224(llaves[i_clase].encode()).hexdigest()\n",
    "    dump(llaves, carpeta_data() + \"/llaves_clases.bin\")\n",
    "\n",
    "def obtener_llaves_clases():\n",
    "    return load(carpeta_data() + \"/llaves_clases.bin\")\n",
    "\n",
    "#%time generar_llaves_clases()\n",
    "\n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Armando folds (archivos fasta)\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.externals.joblib import Parallel, delayed, load\n",
    "\n",
    "def cargar_llaves_clases():\n",
    "    return load(carpeta_data() + \"/llaves_clases.bin\")\n",
    "\n",
    "def carpeta_fold_clase(llave):\n",
    "    return carpeta_fold() + \"/fold_clase_\" + str(llave)\n",
    "\n",
    "def archivo_fold_clase(llave, tipoTrainTest, tipoRNA):\n",
    "    return carpeta_fold_clase(llave) + \"/\" + tipoTrainTest + \"/\" + tipoRNA + \".fa\"\n",
    "\n",
    "def armar_fold_final(tipo):\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    if not os.path.isdir(carpeta_fold_clase(llave)):\n",
    "        os.mkdir(carpeta_fold_clase(llave))\n",
    "    if not os.path.isdir(carpeta_fold_clase(llave) + \"/train\"):\n",
    "        os.mkdir(carpeta_fold_clase(llave) + \"/train\")\n",
    "    with open(archivo_fold_clase(llave, \"train\", tipo), \"w+\") as outfile:\n",
    "        for num_clase in iterador_clases():\n",
    "            with open(archivo_clase(num_clase, tipo), \"r\") as infile:\n",
    "                for inline in infile:\n",
    "                    outfile.write(inline)\n",
    "    \n",
    "def armar_fold_clase(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    os.mkdir(carpeta_fold_clase(llave))\n",
    "    os.mkdir(carpeta_fold_clase(llave) + \"/train\")\n",
    "    for tipo in [\"lncRNA\", \"PCT\", \"CDS\"]:\n",
    "        with open(archivo_fold_clase(llave, \"train\", tipo), \"w+\") as outfile:\n",
    "            for j_num_clase in iterador_clases():\n",
    "                if num_clase != j_num_clase:\n",
    "                    with open(archivo_clase(j_num_clase, tipo)) as infile:\n",
    "                        for inline in infile:\n",
    "                            outfile.write(inline)\n",
    "    os.mkdir(carpeta_fold_clase(llave) + \"/test\")\n",
    "    for tipo in [\"lncRNA\", \"PCT\"]:\n",
    "        with open(archivo_fold_clase(llave, \"test\", tipo), \"w+\") as outfile:\n",
    "            with open(archivo_clase(num_clase, tipo)) as infile:\n",
    "                for inline in infile:\n",
    "                    outfile.write(inline)\n",
    "                    \n",
    "#if os.path.isdir(carpeta_fold()):\n",
    "#    shutil.rmtree(carpeta_fold())\n",
    "#os.mkdir(carpeta_fold())\n",
    "\n",
    "#%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(armar_fold_final)(tipo) for tipo in [\"lncRNA\", \"PCT\", \"CDS\"])\n",
    "#%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(armar_fold_clase)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Generando modelos CPAT de los folds\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_caracteristicas\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_caracteristicas)\n",
    "\n",
    "def carpeta_fold_cpat(llave):\n",
    "    return carpeta_fold_clase(llave) + \"/cpat\"\n",
    "\n",
    "def generar_cpat_fold(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    archivo_CDS = archivo_fold_clase(llave, \"train\", \"CDS\")\n",
    "    carpeta_cpat = carpeta_fold_cpat(llave)\n",
    "    if not os.path.isdir(carpeta_cpat):\n",
    "        os.mkdir(carpeta_cpat)\n",
    "    util_caracteristicas.generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat)\n",
    "    \n",
    "def generar_cpat_final():\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    archivo_CDS = archivo_fold_clase(llave, \"train\", \"CDS\")\n",
    "    carpeta_cpat = carpeta_fold_cpat(llave)\n",
    "    if not os.path.isdir(carpeta_cpat):\n",
    "        os.mkdir(carpeta_cpat)\n",
    "    util_caracteristicas.generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat)\n",
    "\n",
    "def limpieza_archivos_CDS(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    os.remove(archivo_fold_clase(llave, \"train\", \"CDS\"))\n",
    "\n",
    "#%time generar_cpat_final()\n",
    "#%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(generar_cpat_fold)(num_clase) for num_clase in iterador_clases())\n",
    "#%time limpieza_archivos_CDS(0)\n",
    "#%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(limpieza_archivos_CDS)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Ejecutar cpat y diamond sobre los folds\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_caracteristicas\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_caracteristicas)\n",
    "\n",
    "def ejecutar_cpat_fold(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    carpeta_cpat = carpeta_fold_cpat(llave)\n",
    "    util_caracteristicas.ejecutar_cpat(archivo_lncRNA, carpeta_cpat, archivo_lncRNA.replace(\".fa\", \".cpat\"))\n",
    "    os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "    os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".r\")\n",
    "    util_caracteristicas.ejecutar_cpat(archivo_PCT, carpeta_cpat, archivo_PCT.replace(\".fa\", \".cpat\"))\n",
    "    os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "    os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".r\")\n",
    "\n",
    "def ejecutar_cpat_diamond_final():\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    diamond_db = \"./feature_engine/Diamond_BD/uniprot-viridiplantae-reviewed.dmnd\"\n",
    "    carpeta_cpat = carpeta_fold_cpat(llave)\n",
    "    util_caracteristicas.ejecutar_diamond(archivo_lncRNA, diamond_db, archivo_lncRNA.replace(\".fa\", \".dmnd\"))\n",
    "    util_caracteristicas.ejecutar_diamond(archivo_PCT, diamond_db, archivo_PCT.replace(\".fa\", \".dmnd\"))\n",
    "    util_caracteristicas.ejecutar_cpat(archivo_lncRNA, carpeta_cpat, archivo_lncRNA.replace(\".fa\", \".cpat\"))\n",
    "    os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "    os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".r\")\n",
    "    util_caracteristicas.ejecutar_cpat(archivo_PCT, carpeta_cpat, archivo_PCT.replace(\".fa\", \".cpat\"))\n",
    "    os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "    os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".r\")\n",
    "\n",
    "#%time ejecutar_cpat_diamond_final()\n",
    "#%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(ejecutar_cpat_fold)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso finalizado\n"
     ]
    }
   ],
   "source": [
    "#Generar archivo de features por cada fold\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_caracteristicas\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_caracteristicas)\n",
    "\n",
    "def archivo_features_clase(llave, tipoTrainTest, tipoRNA):\n",
    "    return archivo_fold_clase(llave, tipoTrainTest, tipoRNA).replace(\".fa\", \".ft\")\n",
    "\n",
    "def generar_features_fold(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    features_base_lncRNA = archivo_features_clase(obtener_llaves_clases()[0], \"train\", \"lncRNA\")\n",
    "    features_base_PCT = archivo_features_clase(obtener_llaves_clases()[0], \"train\", \"PCT\")\n",
    "    for tipo in [\"train\", \"test\"]:\n",
    "        archivo_lncRNA = archivo_fold_clase(llave, tipo, \"lncRNA\")\n",
    "        archivo_PCT = archivo_fold_clase(llave, tipo, \"PCT\")\n",
    "        archivo_cpat_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\").replace(\".fa\", \".cpat\")\n",
    "        archivo_cpat_PCT = archivo_fold_clase(llave, \"train\", \"PCT\").replace(\".fa\", \".cpat\")\n",
    "        salida_lncRNA = archivo_features_clase(llave, tipo, \"lncRNA\")\n",
    "        salida_PCT = archivo_features_clase(llave, tipo, \"PCT\")\n",
    "        util_caracteristicas.generar_features(archivo_lncRNA, features_base_lncRNA, archivo_cpat_lncRNA, salida_lncRNA)\n",
    "        util_caracteristicas.generar_features(archivo_PCT, features_base_PCT, archivo_cpat_PCT, salida_PCT)\n",
    "    \n",
    "def generar_features_final():\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    archivo_lncRNA = archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "    archivo_PCT = archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "    salida_lncRNA = archivo_features_clase(llave, \"train\", \"lncRNA\")\n",
    "    salida_PCT = archivo_features_clase(llave, \"train\", \"PCT\")\n",
    "    util_caracteristicas.generar_features_base(archivo_lncRNA, archivo_lncRNA.replace(\".fa\", \".cpat\"), archivo_lncRNA.replace(\".fa\", \".dmnd\"), salida_lncRNA)\n",
    "    util_caracteristicas.generar_features_base(archivo_PCT, archivo_PCT.replace(\".fa\", \".cpat\"), archivo_PCT.replace(\".fa\", \".dmnd\"), salida_PCT)\n",
    "\n",
    "#%time generar_features_final()\n",
    "#%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(generar_features_fold)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "#Generar modelo final\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV\n",
    "from sklearn.externals.joblib import dump, load\n",
    "import hashlib\n",
    "import util_fasta\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util_fasta)\n",
    "\n",
    "def obtener_data_entrenamiento():\n",
    "    llave = obtener_llaves_clases()[0]\n",
    "    codigos_lncRNA = util_fasta.leer_fasta_list(archivo_fold_clase(llave, \"train\", \"lncRNA\"))\n",
    "    codigos_PCT = util_fasta.leer_fasta_list(archivo_fold_clase(llave, \"train\", \"PCT\"))\n",
    "    \n",
    "    codigos_lncRNA = [(x[0],\"\") for x in codigos_lncRNA]\n",
    "    codigos_PCT = [(x[0],\"\") for x in codigos_PCT]\n",
    "    \n",
    "    y = ([1] * len(codigos_lncRNA)) + ([0] * len(codigos_PCT))\n",
    "    groups = list()\n",
    "    for _ in range(2):\n",
    "        for num_clase in iterador_clases():\n",
    "            groups += ([num_clase] * (cantidad_transcritos))\n",
    "    return codigos_lncRNA + codigos_PCT, y, groups\n",
    "\n",
    "class GeneradorFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cantidad_transcritos=None, num_clases=None):\n",
    "        if cantidad_transcritos is None:\n",
    "            return\n",
    "        self.cantidad_transcritos = cantidad_transcritos\n",
    "        self.num_clases = num_clases\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self._llave_fold = self.obtener_llave_fold(X)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self.obtener_features_pre_calculados(X)\n",
    "    \n",
    "    def obtener_llave_fold(self, X):\n",
    "        cod_secuencias = \"\"\n",
    "        cod_secuencias2 = \"\"\n",
    "        num_transcritos = len(X)\n",
    "        num_transcritos_por_grupo = self.cantidad_transcritos\n",
    "        for i in range(num_transcritos//(num_transcritos_por_grupo*2)):\n",
    "            cod_secuencias += X[i * num_transcritos_por_grupo][0]\n",
    "            cod_secuencias2 += X[i * num_transcritos_por_grupo][0] + \"*****\"\n",
    "        llave = hashlib.sha224(cod_secuencias.encode()).hexdigest()\n",
    "        return llave\n",
    "    \n",
    "    def obtener_features_pre_calculados(self, X):\n",
    "        llave = self._llave_fold\n",
    "        tipo = \"train\"\n",
    "        if os.path.isfile(archivo_fold_clase(llave, \"test\", \"lncRNA\")):\n",
    "            secuencias = util_fasta.leer_fasta(archivo_fold_clase(llave, \"test\", \"lncRNA\"), 1)\n",
    "            if list(secuencias.keys())[0] == X[0][0]:\n",
    "                tipo = \"test\"\n",
    "        features = list(load(archivo_features_clase(llave, tipo, \"lncRNA\")).values())\n",
    "        features += list(load(archivo_features_clase(llave, tipo, \"PCT\")).values())\n",
    "        return [list(x.values()) for x in features]\n",
    "\n",
    "def generar_modelo_final(tuned_parameters):\n",
    "    X_train, y_train, groups = obtener_data_entrenamiento()\n",
    "    svm_pipeline = Pipeline(steps=[('features', GeneradorFeatures(cantidad_transcritos, obtener_num_clases())), ('svc', SVC())])\n",
    "    logo = LeaveOneGroupOut()\n",
    "    clf = GridSearchCV(svm_pipeline, tuned_parameters, cv=logo, scoring=score, n_jobs=n_jobs, refit=\"accuracy\", return_train_score = True, verbose=verbose)\n",
    "    clf.fit(X_train, y_train, groups) #requerido por LeaveOneGroupOut\n",
    "    resultado = {\n",
    "        \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "        \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "        \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "    }\n",
    "    dump(resultado, carpeta_modelo() + \"/resultado.bin\")\n",
    "    dump(clf.best_params_, carpeta_modelo() + \"/params.bin\")\n",
    "    dump(clf.cv_results_, carpeta_modelo() + \"/cv_results.bin\")\n",
    "    dump(clf.best_estimator_, carpeta_modelo() + \"/modelo.plk\")\n",
    "\n",
    "def prueba_de_modelo_final():\n",
    "    X_train, y_train, groups = obtener_data_entrenamiento()\n",
    "    svm_pipeline = Pipeline(steps=[('features', GeneradorFeatures(cantidad_transcritos, obtener_num_clases())), ('svc', SVC(kernel=\"rbf\",gamma=1e-3,C=2,verbose=verbose))])\n",
    "    svm_pipeline.fit(X_train, y_train)\n",
    "    dump(svm_pipeline, carpeta_modelo() + \"/modelo2.plk\")\n",
    "    \n",
    "if not os.path.isdir(carpeta_modelo()):\n",
    "    #shutil.rmtree(carpeta_modelo())\n",
    "    os.mkdir(carpeta_modelo())\n",
    "\n",
    "%time prueba_de_modelo_final()\n",
    "#%time generar_modelo_final(tuned_parameters)\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "def limpieza_archivos_finales_fasta_ruta(llave):\n",
    "    shutil.rmtree(carpeta_fold_clase(llave))\n",
    "    \n",
    "def limpieza_archivos_finales_fasta(num_clase):\n",
    "    llave = obtener_llaves_clases()[num_clase]\n",
    "    if num_clase == 0:\n",
    "        shutil.rmtree(carpeta_fold_clase(llave) + \"/train\")\n",
    "    else:\n",
    "        limpieza_archivos_finales_fasta_ruta(llave)\n",
    "        \n",
    "#%time limpieza_archivos_finales_fasta(0)\n",
    "#%time Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(limpieza_archivos_finales_fasta)(num_clase) for num_clase in iterador_clases())\n",
    "    \n",
    "print(\"Proceso finalizado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
