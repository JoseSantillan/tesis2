{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/jose/anaconda3/lib/python3.7/site-packages (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/jose/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/jose/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./libs/util_modelo_referencial_old.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./libs/util_modelo_referencial_old.py\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import util_caracteristicas, util_fasta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals.joblib import dump, load\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def crear_modelo_referencial(identificador, tuned_parameters, scores, n_jobs):\n",
    "    #print(\"lectura de archivos fasta...\")\n",
    "    \n",
    "    codigos_lncRNA = util_fasta.leer_fasta(\"./data/\" + identificador + \".lncRNA.fasta\")\n",
    "    codigos_PCT = util_fasta.leer_fasta(\"./data/\" + identificador + \".PCT.fasta\")\n",
    "    \n",
    "    #print(\"levantamiento de features...\")\n",
    "    \n",
    "    util_caracteristicas.generar_modelo_CPAT(identificador, codigos_lncRNA.keys(), codigos_PCT.keys())\n",
    "    \n",
    "    dict_features_lncRNA = util_caracteristicas.generar_caracteristicas(identificador, codigos_lncRNA)\n",
    "    dict_features_PCT = util_caracteristicas.generar_caracteristicas(identificador, codigos_PCT)\n",
    "    \n",
    "    features_lncRNA = [list(x.values()) for x in dict_features_lncRNA.values()]\n",
    "    features_PCT = [list(x.values()) for x in dict_features_PCT.values()]\n",
    "    \n",
    "    #print(\"inicio generaci√≥n del modelo...\")\n",
    "    \n",
    "    X = features_lncRNA + features_PCT\n",
    "    y = ([1] * len(features_lncRNA)) + ([0] * len(features_PCT))\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "    X_train, y_train = shuffle(X, y, random_state=0)\n",
    "    \n",
    "    #feature_scaler = StandardScaler()\n",
    "    #feature_scaler=load('./modelos_referenciales/feature_scaler_{}.bin'.format(identificador))\n",
    "    #X_train = feature_scaler.fit_transform(X_train)  \n",
    "    #X_test = feature_scaler.transform(X_test)\n",
    "    #dump(feature_scaler, './modelos_referenciales/feature_scaler_{}.bin'.format(identificador), compress=True)\n",
    "    \n",
    "    for score in scores:\n",
    "        #print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        #print()\n",
    "\n",
    "        clf = GridSearchCV(SVC(), tuned_parameters, cv=10,\n",
    "                           scoring=score, n_jobs=n_jobs, refit=\"accuracy\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        dump(clf.best_estimator_, './modelos_referenciales/modelo_{}.pkl'.format(identificador), compress = 1)\n",
    "        #clf=load('./modelos_referenciales/{}.pkl'.format(identificador))\n",
    "\n",
    "        #print(\"Best parameters set found on development set:\")\n",
    "        #print()\n",
    "        #print(clf.best_params_)\n",
    "        #print()\n",
    "        #print(\"Grid scores on development set:\")\n",
    "        #print()\n",
    "        \n",
    "        resultado = {\n",
    "            \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "            \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "            \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "        }\n",
    "        dump(resultado, './modelos_referenciales/resultado_{}.bin'.format(identificador))\n",
    "        \n",
    "        #means = clf.cv_results_['mean_test_accuracy']\n",
    "        #stds = clf.cv_results_['std_test_accuracy']\n",
    "        #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        #          % (mean, std * 2, params))\n",
    "        #print()\n",
    "\n",
    "        #print(\"Detailed classification report:\")\n",
    "        #print()\n",
    "        #print(\"The model is trained on the full development set.\")\n",
    "        #print(\"The scores are computed on the full evaluation set.\")\n",
    "        #print()\n",
    "        #y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        #print(classification_report(y_true, y_pred))\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./libs/util_modelo_referencial.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./libs/util_modelo_referencial.py\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import util_caracteristicas, util_fasta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals.joblib import dump, load\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "class GeneradorFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, identificador=None):\n",
    "        self.identificador = identificador\n",
    "        self.random_id = identificador + \"_fold_\" + ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        identificador = self.random_id\n",
    "        codigos_lncRNA = {}\n",
    "        codigos_PCT = {}\n",
    "        for i in range(len(X)):\n",
    "            if y[i] == 0:\n",
    "                codigos_PCT[X[i][0]] = X[i][1]\n",
    "            else:\n",
    "                codigos_lncRNA[X[i][0]] = X[i][1]\n",
    "        util_caracteristicas.generar_modelo_CPAT(identificador, codigos_lncRNA, codigos_PCT)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        identificador = self.random_id\n",
    "        codigos = {codigo[0]:codigo[1] for codigo in X}\n",
    "        dict_features = util_caracteristicas.generar_caracteristicas(identificador, codigos)\n",
    "\n",
    "        return [list(x.values()) for x in dict_features.values()]\n",
    "\n",
    "def crear_modelo_referencial(identificador, tuned_parameters, scores, n_jobs):\n",
    "    codigos_lncRNA = util_fasta.leer_fasta(\"./data/\" + identificador + \".lncRNA.fasta\")\n",
    "    codigos_PCT = util_fasta.leer_fasta(\"./data/\" + identificador + \".PCT.fasta\")\n",
    "    \n",
    "    X = list(codigos_lncRNA.items()) + list(codigos_PCT.items())\n",
    "    y = ([1] * len(codigos_lncRNA)) + ([0] * len(codigos_PCT))\n",
    "    X_train, y_train = shuffle(X, y, random_state=0)\n",
    "    cachedir = mkdtemp()\n",
    "    svm_pipeline = Pipeline(steps=[('features', GeneradorFeatures(identificador)), ('svc', SVC())], memory=cachedir)\n",
    "    \n",
    "    for score in scores:\n",
    "        clf = GridSearchCV(svm_pipeline, tuned_parameters, cv=10, scoring=score, n_jobs=n_jobs, refit=\"accuracy\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        resultado = {\n",
    "            \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "            \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "            \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "        }\n",
    "        dump(resultado, './modelos_referenciales/resultado_{}.bin'.format(identificador))\n",
    "        \n",
    "        #means = clf.cv_results_['mean_test_accuracy']\n",
    "        #stds = clf.cv_results_['std_test_accuracy']\n",
    "        #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        #          % (mean, std * 2, params))\n",
    "        #print()\n",
    "\n",
    "        #print(\"Detailed classification report:\")\n",
    "        #print()\n",
    "        #print(\"The model is trained on the full development set.\")\n",
    "        #print(\"The scores are computed on the full evaluation set.\")\n",
    "        #print()\n",
    "        #y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        #print(classification_report(y_true, y_pred))\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso...\n",
      "{'accuracy': 0.903041825095057, 'precision': 0.8570791181000229, 'recall': 0.967680608365019}\n",
      "Proceso terminado...\n",
      "CPU times: user 23.4 s, sys: 317 ms, total: 23.7 s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_modelo_referencial\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.externals.joblib import load\n",
    "\n",
    "print(\"Iniciando proceso...\")\n",
    "identificador = \"Especie2\"\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "scores = ['precision_macro', 'recall_macro', 'accuracy']\n",
    "#2.43 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [1]}]\n",
    "#3.40 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [10]}]\n",
    "#13.00 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [100]}]\n",
    "#4.18 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [1, 10]}] #n_jobs=None\n",
    "#3.7 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [1, 10]}] #n_jobs=-1\n",
    "#8.34 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [100]}]\n",
    "#no_termina tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [1000]}]\n",
    "#3.03 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-4], 'C': [1, 10, 100]}]\n",
    "#no_termina tuned_parameters = [{'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "#no_termina tuned_parameters = [{'kernel': ['linear'], 'C': [1]}]\n",
    "#no_termina tuned_parameters = [{'kernel': ['linear'], 'C': [10]}]\n",
    "#no_termina tuned_parameters = [{'kernel': ['linear'], 'C': [100]}]\n",
    "#no_termina tuned_parameters = [{'kernel': ['linear'], 'C': [1000]}]\n",
    "#\n",
    "#25.16 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [1,10,20,30,40,50,60,70,80,90,100]}]\n",
    "#3.15 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [0.1,0.5,0.9,1]}]\n",
    "#best tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3], 'C': [0.1,1,2]}]\n",
    "#3.00 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-4,1e-5], 'C': [0.01,0.1,1,10]}]\n",
    "#3.39 tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-5,1e-6], 'C': [10,15,20,100]}]\n",
    "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-5], 'C': [60,80,100,120,140]}]\n",
    "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-5], 'C': [900,1000,5000,10000]}]\n",
    "tuned_parameters = [{'svc__kernel': ['rbf'], 'svc__gamma': [1e-3], 'svc__C': [0.1,0.5,0.9,2], 'features__identificador': [identificador]}]\n",
    "scores = [['accuracy','precision','recall']]\n",
    "util_modelo_referencial.crear_modelo_referencial(identificador, tuned_parameters, scores, n_jobs=-1)\n",
    "print(load('./modelos_referenciales/resultado_{}.bin'.format(identificador)))\n",
    "\n",
    "print(\"Proceso terminado...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
