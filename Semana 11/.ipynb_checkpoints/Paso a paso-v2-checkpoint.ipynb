{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_especies = 3\n",
    "cantidad_transcritos = 4000\n",
    "carpeta_data = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generaci√≥n de archivos fasta para las 30 especies\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_bd, util_fasta\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.externals.joblib import Parallel, delayed, dump\n",
    "\n",
    "def obtener_especies():\n",
    "    query = \"SELECT * FROM (SELECT CONVERT(@row_number:=@row_number + 1, UNSIGNED) AS orden, m.id_especie, m.especie FROM especies_seleccionadas s JOIN maestra_especies m ON s.especie = m.especie, (SELECT @row_number:=0) AS rn ORDER BY m.id_especie) a ORDER BY 1 LIMIT \" + str(cantidad_especies)\n",
    "    return util_bd.resultados_query(query)\n",
    "        \n",
    "def generar_fasta_especie( row_especie):\n",
    "    os.mkdir(carpeta_data + \"/clase_\" + str(row_especie[0]))\n",
    "    # lncRNA\n",
    "    query = \"SELECT cod_secuencia, secuencia FROM secuencias WHERE flg_pct = 0 AND flg_seleccionado = 1 AND id_especie = \" + str(row_especie[1]) + \" ORDER BY cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data + \"/clase_\" + str(row_especie[0]) + \"/lncRNA.fa\")\n",
    "    # PCT\n",
    "    query = \"SELECT cod_secuencia, secuencia FROM secuencias WHERE flg_pct = 1 AND flg_seleccionado = 1 AND id_especie = \" + str(row_especie[1]) + \" ORDER BY cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data + \"/clase_\" + str(row_especie[0]) + \"/PCT.fa\")\n",
    "    # CDS\n",
    "    query = \"SELECT f.cod_secuencia, cds.coding FROM secuencias_CDS cds JOIN secuencias_features f ON cds.id_especie = f.id_especie AND cds.cod_secuencia = f.cod_secuencia WHERE f.flg_pct = 1 AND f.flg_seleccionado = 1 AND f.id_especie = \" + str(row_especie[1]) + \" ORDER BY f.cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data + \"/clase_\" + str(row_especie[0]) + \"/CDS.fa\")\n",
    "\n",
    "if os.path.isdir(carpeta_data):\n",
    "    shutil.rmtree(carpeta_data)\n",
    "os.mkdir(carpeta_data)\n",
    "\n",
    "%time dump(obtener_especies(), carpeta_data + \"/info_clases.bin\")\n",
    "%time Parallel(n_jobs=4, verbose=0)(delayed(generar_fasta_especie)(row_especie) for row_especie in obtener_especies())\n",
    "\n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c anaconda tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c anaconda cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_caracteristicas\n",
    "from numpy import array\n",
    "\n",
    "carpeta_features = \"./features\"\n",
    "if os.path.isdir(carpeta_features):\n",
    "    shutil.rmtree(carpeta_features)\n",
    "os.mkdir(carpeta_features)\n",
    "os.mkdir(carpeta_features + \"/cpat\")\n",
    "os.mkdir(carpeta_features + \"/diamond\")\n",
    "\n",
    "tipo = \"train\"\n",
    "archivo_lncRNA = carpeta_data + \"/clase_1/lncRNA.fa\"\n",
    "archivo_PCT = carpeta_data + \"/clase_1/PCT.fa\"\n",
    "archivo_CDS = carpeta_data + \"/clase_1/CDS.fa\"\n",
    "carpeta_cpat = carpeta_features + \"/cpat\"\n",
    "util_caracteristicas.generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "diamond_db = \"./feature_engine/Diamond_BD/uniprot-viridiplantae-reviewed.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/diamond/\" + tipo + \"_lncRNA.dmnd\"\n",
    "util_caracteristicas.ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_salida = carpeta_features + \"/diamond/\" + tipo + \"_PCT.dmnd\"\n",
    "util_caracteristicas.ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "archivo_salida = carpeta_features + \"/cpat/\" + tipo + \"_lncRNA.cpat\"\n",
    "util_caracteristicas.ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_salida = carpeta_features + \"/cpat/\" + tipo + \"_PCT.cpat\"\n",
    "util_caracteristicas.ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "archivo_cpat = carpeta_features + \"/cpat/\" + tipo + \"_lncRNA.cpat\"\n",
    "archivo_diamond = carpeta_features + \"/diamond/\" + tipo + \"_lncRNA.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/\" + tipo + \"_lncRNA.ft\"\n",
    "util_caracteristicas.generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_cpat = carpeta_features + \"/cpat/\" + tipo + \"_PCT.cpat\"\n",
    "archivo_diamond = carpeta_features + \"/diamond/\" + tipo + \"_PCT.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/\" + tipo + \"_PCT.ft\"\n",
    "util_caracteristicas.generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida)\n",
    "\n",
    "tipo = \"test\"\n",
    "archivo_lncRNA = carpeta_data + \"/clase_2/lncRNA.fa\"\n",
    "archivo_PCT = carpeta_data + \"/clase_2/PCT.fa\"\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "diamond_db = \"./feature_engine/Diamond_BD/uniprot-viridiplantae-reviewed.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/diamond/\" + tipo + \"_lncRNA.dmnd\"\n",
    "util_caracteristicas.ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_salida = carpeta_features + \"/diamond/\" + tipo + \"_PCT.dmnd\"\n",
    "util_caracteristicas.ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "archivo_salida = carpeta_features + \"/cpat/\" + tipo + \"_lncRNA.cpat\"\n",
    "util_caracteristicas.ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_salida = carpeta_features + \"/cpat/\" + tipo + \"_PCT.cpat\"\n",
    "util_caracteristicas.ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "archivo_cpat = carpeta_features + \"/cpat/\" + tipo + \"_lncRNA.cpat\"\n",
    "archivo_diamond = carpeta_features + \"/diamond/\" + tipo + \"_lncRNA.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/\" + tipo + \"_lncRNA.ft\"\n",
    "util_caracteristicas.generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_cpat = carpeta_features + \"/cpat/\" + tipo + \"_PCT.cpat\"\n",
    "archivo_diamond = carpeta_features + \"/diamond/\" + tipo + \"_PCT.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/\" + tipo + \"_PCT.ft\"\n",
    "util_caracteristicas.generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import load\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "carpeta_features = \"./features\"\n",
    "\n",
    "features_train_lncRNA = load(carpeta_features + \"/train_lncRNA.ft\")\n",
    "features_train_PCT = load(carpeta_features + \"/train_PCT.ft\")\n",
    "features_test_lncRNA = load(carpeta_features + \"/test_lncRNA.ft\")\n",
    "features_test_PCT = load(carpeta_features + \"/test_PCT.ft\")\n",
    "\n",
    "features_train = [list(x.values()) for x in list(features_train_lncRNA.values()) + list(features_train_PCT.values())]\n",
    "features_test = [list(x.values()) for x in list(features_test_lncRNA.values()) + list(features_test_PCT.values())]\n",
    "        \n",
    "x_train = np.array(features_train)\n",
    "y_train = np.array(([1] * len(features_train_lncRNA)) + ([0] * len(features_train_PCT)))\n",
    "x_test = np.array(features_test)\n",
    "y_test = np.array(([1] * len(features_test_lncRNA)) + ([0] * len(features_test_PCT)))\n",
    "\n",
    "x_train = RobustScaler().fit_transform(x_train)\n",
    "x_test = RobustScaler().fit_transform(x_test)\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def create_model(optimizer='adam', learn_rate=0.01, momentum=0, init_mode='uniform', activation='relu', activation2='softmax', dropout_rate=0.0, weight_constraint=1, neurons=10):\n",
    "    #optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=10, activation=activation, input_dim=10, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=neurons, activation=activation2, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer=init_mode))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "batch_size = [2**6, 2**8, 2**10]\n",
    "epochs = [10, 50, 100]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "tuned_parameters = [{'batch_size': [2**10], 'epochs': [2**10], 'optimizer': ['SGD', 'Adam'], 'learn_rate': [0.01], 'momentum': [0], 'init_mode': ['uniform'], 'activation': ['relu'], 'activation': ['softmax'], 'dropout_rate': [0.0], 'weight_constraint': [1], 'neurons': [10, 100]}]\n",
    "#tuned_parameters = [{'batch_size': batch_size, 'epochs': epochs, 'optimizer': optimizer, 'learn_rate': learn_rate, 'momentum': momentum, 'init_mode': init_mode, 'activation': activation, 'activation2': activation, 'dropout_rate': dropout_rate, 'weight_constraint': weight_constraint, 'neurons': neurons}]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, cv=10, scoring=['accuracy','precision','recall'], n_jobs=4, refit=\"accuracy\", return_train_score = True, verbose=0)\n",
    "%time clf.fit(x_train, y_train)\n",
    "resultado = {\n",
    "    \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "    \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "    \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "}\n",
    "print(resultado)\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "\n",
    "#clf = model\n",
    "#clf.fit(x_train, y_train, batch_size=2**10, epochs=2**13)\n",
    "\n",
    "#history = model.fit(x_train, y_train, verbose=0)\n",
    "#plt.plot(history.history['loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "def create_model(optimizer='adam', learn_rate=0.01, momentum=0, init_mode='uniform', activation='relu', activation2='softmax', dropout_rate=0.0, weight_constraint=1, neurons=10):\n",
    "    #optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=10, activation=activation, input_dim=10, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=neurons, activation=activation2, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer=init_mode))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "batch_size = [2**6, 2**8, 2**10]\n",
    "epochs = [10, 50, 100]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "tuned_parameters = [{'batch_size': [2**10], 'epochs': [2**10], 'optimizer': ['SGD', 'Adam'], 'learn_rate': [0.01], 'momentum': [0], 'init_mode': ['uniform'], 'activation': ['relu'], 'activation': ['softmax'], 'dropout_rate': [0.0], 'weight_constraint': [1], 'neurons': [10, 100]}]\n",
    "#tuned_parameters = [{'batch_size': batch_size, 'epochs': epochs, 'optimizer': optimizer, 'learn_rate': learn_rate, 'momentum': momentum, 'init_mode': init_mode, 'activation': activation, 'activation2': activation, 'dropout_rate': dropout_rate, 'weight_constraint': weight_constraint, 'neurons': neurons}]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, cv=10, scoring=['accuracy','precision','recall'], n_jobs=4, refit=\"accuracy\", return_train_score = True, verbose=0)\n",
    "%time clf.fit(x_train, y_train)\n",
    "resultado = {\n",
    "    \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "    \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "    \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "}\n",
    "print(resultado)\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "\n",
    "#clf = model\n",
    "#clf.fit(x_train, y_train, batch_size=2**10, epochs=2**13)\n",
    "\n",
    "#history = model.fit(x_train, y_train, verbose=0)\n",
    "#plt.plot(history.history['loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, precision_recall_curve, average_precision_score\n",
    "\n",
    "y_true = clf.predict(x_test)\n",
    "print(confusion_matrix(y_true, y_test))\n",
    "print(classification_report(y_true, y_test, target_names=[\"lncRNA\", \"PCT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "predicted = clf.predict_proba(x_test)\n",
    "probs = predicted[:,1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "average_precision = average_precision_score(y_test, probs)\n",
    "plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
