{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if not os.path.isdir(\"./libs\"):\n",
    "    os.mkdir(\"./libs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./libs/util_bd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./libs/util_bd.py\n",
    "import mysql.connector\n",
    "import myloginpath\n",
    "import pandas as pd\n",
    "\n",
    "def resultados_query(query):\n",
    "    conf = myloginpath.parse('tesis2')\n",
    "    conn = mysql.connector.connect(**conf, db=\"tesis2\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    resultado = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return resultado\n",
    "\n",
    "def ejecutar_query(query):\n",
    "    conf = myloginpath.parse('tesis2')\n",
    "    conn = mysql.connector.connect(**conf, db=\"tesis2\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    conn.close()\n",
    "\n",
    "def mostrar_resultado_query(query):\n",
    "    conf = myloginpath.parse('tesis2')\n",
    "    conn = mysql.connector.connect(**conf, db=\"tesis2\")\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    display(df)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./libs/util_fasta.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./libs/util_fasta.py\n",
    "import os\n",
    "\n",
    "def generar_fasta(secuencias, archivo, tamanio_por_linea=80):\n",
    "    t_tamanio = tamanio_por_linea\n",
    "    f = open(archivo ,\"w+\")\n",
    "    for transcrito in secuencias:\n",
    "        f.write(\">%s\\n\" % (transcrito[0].strip().upper()))\n",
    "        seq = transcrito[1]\n",
    "        t_partes = [seq[i:i+t_tamanio] for i in range(0, len(seq), t_tamanio)]\n",
    "        for t_parte in t_partes:\n",
    "            f.write(\"%s\\n\" % (t_parte))\n",
    "    f.close()\n",
    "\n",
    "def leer_fasta(archivo, limite = 0):\n",
    "    transcritos = {}\n",
    "    cod_secuencia = \"\"\n",
    "    secuencia = \"\"\n",
    "    f = open(archivo, \"r\")\n",
    "    for linea in f:\n",
    "        if linea.startswith(\">\"):\n",
    "            if secuencia != \"\":\n",
    "                transcritos[cod_secuencia] = secuencia\n",
    "                secuencia = \"\"\n",
    "                limite -= 1\n",
    "                if limite == 0:\n",
    "                    break\n",
    "            cod_secuencia = linea.rstrip(\"\\n\").lstrip(\">\").strip().upper()\n",
    "        else:\n",
    "            secuencia += linea.rstrip(\"\\n\")\n",
    "    if secuencia != \"\":\n",
    "        transcritos[cod_secuencia] = secuencia\n",
    "        secuencia = \"\"\n",
    "    f.close()\n",
    "    return transcritos\n",
    "\n",
    "def leer_fasta_list(archivo, limite = 0):\n",
    "    transcritos = list()\n",
    "    cod_secuencia = \"\"\n",
    "    secuencia = \"\"\n",
    "    f = open(archivo, \"r\")\n",
    "    for linea in f:\n",
    "        if linea.startswith(\">\"):\n",
    "            if secuencia != \"\":\n",
    "                transcritos.append((cod_secuencia, secuencia))\n",
    "                secuencia = \"\"\n",
    "                limite -= 1\n",
    "                if limite == 0:\n",
    "                    break\n",
    "            cod_secuencia = linea.rstrip(\"\\n\").lstrip(\">\").strip().upper()\n",
    "        else:\n",
    "            secuencia += linea.rstrip(\"\\n\")\n",
    "    if secuencia != \"\":\n",
    "        transcritos.append((cod_secuencia, secuencia))\n",
    "        secuencia = \"\"\n",
    "    f.close()\n",
    "    return transcritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./libs/util_caracteristicas.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./libs/util_caracteristicas.py\n",
    "import os\n",
    "import util_fasta\n",
    "from Bio.SeqUtils import GC\n",
    "import csv\n",
    "from sklearn.externals.joblib import dump, load\n",
    "\n",
    "def generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat):\n",
    "    _generar_modelo_CPAT_hexamer(archivo_lncRNA, archivo_CDS, carpeta_cpat)\n",
    "    _generar_modelo_CPAT_logit(archivo_lncRNA, archivo_PCT, carpeta_cpat)\n",
    "\n",
    "def _generar_modelo_CPAT_hexamer(archivo_lncRNA, archivo_CDS, carpeta_cpat):\n",
    "    script = \"~/anaconda3/bin/make_hexamer_tab.py\"\n",
    "    fasta_cds = \"'\" + archivo_CDS + \"'\" \n",
    "    fasta_lncRNA = \"'\" + archivo_lncRNA + \"'\"\n",
    "    salida = \"'\" + carpeta_cpat + \"/hexamer.tsv\" + \"'\"\n",
    "    comando = \"{} -c {} -n {} > {}\".format(script, fasta_cds, fasta_lncRNA, salida)\n",
    "    os.system(comando)\n",
    "    \n",
    "def _generar_modelo_CPAT_logit(archivo_lncRNA, archivo_PCT, carpeta_cpat):\n",
    "    script = \"~/anaconda3/bin/make_logitModel.py\"\n",
    "    hexamer = \"'\" + carpeta_cpat + \"/hexamer.tsv\" + \"'\"\n",
    "    fasta_pct = \"'\" + archivo_PCT + \"'\" \n",
    "    fasta_lncRNA = \"'\" + archivo_lncRNA + \"'\"\n",
    "    salida = \"'\" + carpeta_cpat + \"/fold\" + \"'\"\n",
    "    comando = \"{} -x {} -c {} -n {} -o {}\".format(script, hexamer, fasta_pct, fasta_lncRNA, salida)\n",
    "    os.system(comando)\n",
    "    \n",
    "def ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida):\n",
    "    script = \"~/anaconda3/bin/diamond\"\n",
    "    diamond_bd = \"'\" + diamond_db + \"'\"\n",
    "    salida = \"'\" + archivo_salida + \"'\"\n",
    "    comando = \"{} blastx -d {} -q {} -o {} -k 5 --gapopen 11 --gapextend 1 --more-sensitive -f 6 qseqid pident length qframe qstart qend sstart send evalue bitscore\".format(script, diamond_bd, archivo_entrada, salida)\n",
    "    os.system(comando)\n",
    "\n",
    "def ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida):\n",
    "    script = \"~/anaconda3/bin/cpat.py\"\n",
    "    logit = \"'\" + carpeta_cpat + \"/fold.logit.RData\" + \"'\"\n",
    "    hexamer = \"'\" + carpeta_cpat + \"/hexamer.tsv\" + \"'\"\n",
    "    salida = \"'\" + archivo_salida + \"'\"\n",
    "    comando = \"{} -g {} -d {} -x {} -o {}\".format(script, archivo_entrada, logit, hexamer, salida)\n",
    "    os.system(comando)\n",
    "    \n",
    "def generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida):\n",
    "    transcritos = util_fasta.leer_fasta(archivo_entrada)\n",
    "    transcript_dict = {}\n",
    "    for k in transcritos.keys():\n",
    "        transcript_dict[k.strip().upper()] = {\n",
    "            \"length\" : len(transcritos[k]),\n",
    "            \"gc\" : GC(transcritos[k]),\n",
    "            \"orf_length\" : 0,\n",
    "            \"orf_coverage\" : float(0),\n",
    "            \"hexamer_score\" : float(0),\n",
    "            \"fickett_score\" : float(0),\n",
    "            \"identity\" : float(0),\n",
    "            \"align_length\" : float(0),\n",
    "            \"align_perc_len\" : float(0),\n",
    "            \"align_perc_orf\" : float(0)\n",
    "        }\n",
    "    \n",
    "    #adaptado de https://github.com/gbgolding/crema/blob/master/bin/featuresetup_module.py\n",
    "    with open(archivo_cpat, \"r\") as f:\n",
    "        cpat_reader = csv.reader(f, delimiter=(\"\\t\"))\n",
    "        next(cpat_reader, None) # skip header\n",
    "        for row in cpat_reader:\n",
    "            cod_secuencia = row[0]\n",
    "            transcript_dict[cod_secuencia][\"orf_length\"] = float(row[2])\n",
    "            transcript_dict[cod_secuencia][\"orf_coverage\"] = float(row[2])/float(transcript_dict[cod_secuencia][\"length\"])\n",
    "            transcript_dict[cod_secuencia][\"fickett_score\"] = float(row[3])\n",
    "            transcript_dict[cod_secuencia][\"hexamer_score\"] = float(row[4])\n",
    "    \n",
    "    with open(archivo_diamond, \"r\") as f:\n",
    "        tab_reader = csv.reader(f, delimiter=(\"\\t\"))\n",
    "        line_1 = next(tab_reader)\n",
    "        first = line_1[0].upper()\n",
    "        score = [float(line_1[9])]\n",
    "        with_len = [[first, float(line_1[1]), float(line_1[2]), float(line_1[3]), float(line_1[9])]] # name identity length frame score\n",
    "        for row in tab_reader:\n",
    "            if row[0].upper() == first:\n",
    "                score.append(float(row[9]))\n",
    "                with_len.append([row[0].upper(), float(row[1]), float(row[2]), float(row[3]), float(row[9])])\n",
    "            else:\n",
    "                transcript_dict[first][\"identity\"] = float(0)\n",
    "                transcript_dict[first][\"align_length\"] = float(0)\n",
    "                max_value = max(score)\n",
    "                max_index = score.index(max_value)\n",
    "                max_len_ident = with_len[max_index]\n",
    "                if max_len_ident[3] > 0:\n",
    "                    transcript_dict[first][\"identity\"] = float(max_len_ident[1])\n",
    "                    transcript_dict[first][\"align_length\"] = float(max_len_ident[2])\n",
    "                    transcript_dict[first][\"align_perc_len\"] = float(transcript_dict[first][\"align_length\"]/transcript_dict[first][\"length\"])\n",
    "                    transcript_dict[first][\"align_perc_orf\"] = (0 if transcript_dict[first][\"orf_length\"] == 0 else float(transcript_dict[first][\"align_length\"]/transcript_dict[first][\"orf_length\"]))\n",
    "                score = [float(row[9])]\n",
    "                first = row[0].upper()\n",
    "                with_len = [[first, float(row[1]), float(row[2]), float(row[3]), float(row[9])]]\n",
    "        transcript_dict[first][\"identity\"] = float(0)\n",
    "        transcript_dict[first][\"align_length\"] = float(0)\n",
    "        max_value = max(score)\n",
    "        max_index = score.index(max_value)\n",
    "        max_len_ident = with_len[max_index]\n",
    "        if max_len_ident[3] > 0:\n",
    "            transcript_dict[first][\"identity\"] = float(max_len_ident[1])\n",
    "            transcript_dict[first][\"align_length\"] = float(max_len_ident[2])\n",
    "    #fin de cÃ³digo adaptado de https://github.com/gbgolding/crema/blob/master/bin/featuresetup_module.py\n",
    "    \n",
    "    dump(transcript_dict, archivo_salida)\n",
    "\n",
    "def generar_features(archivo_entrada, features_base, archivo_cpat, archivo_salida):\n",
    "    transcritos = util_fasta.leer_fasta(archivo_entrada)\n",
    "    features_globales = load(features_base)\n",
    "    transcript_dict = {}\n",
    "    for k in transcritos.keys():\n",
    "        transcript_dict[k.strip().upper()] = {\n",
    "            \"length\" : features_globales[k.strip().upper()][\"length\"],\n",
    "            \"gc\" : features_globales[k.strip().upper()][\"gc\"],\n",
    "            \"orf_length\" : features_globales[k.strip().upper()][\"orf_length\"],\n",
    "            \"orf_coverage\" : features_globales[k.strip().upper()][\"orf_coverage\"],\n",
    "            \"hexamer_score\" : float(0),\n",
    "            \"fickett_score\" : float(0),\n",
    "            \"identity\" : features_globales[k.strip().upper()][\"identity\"],\n",
    "            \"align_length\" : features_globales[k.strip().upper()][\"align_length\"],\n",
    "            \"align_perc_len\" : features_globales[k.strip().upper()][\"align_perc_len\"],\n",
    "            \"align_perc_orf\" : features_globales[k.strip().upper()][\"align_perc_orf\"]\n",
    "        }\n",
    "    \n",
    "    with open(archivo_cpat, \"r\") as f:\n",
    "        cpat_reader = csv.reader(f, delimiter=(\"\\t\"))\n",
    "        next(cpat_reader, None) # skip header\n",
    "        for row in cpat_reader:\n",
    "            cod_secuencia = row[0].strip().upper()\n",
    "            if cod_secuencia in transcript_dict:\n",
    "                transcript_dict[cod_secuencia][\"fickett_score\"] = float(row[3])\n",
    "                transcript_dict[cod_secuencia][\"hexamer_score\"] = float(row[4])\n",
    "                \n",
    "    dump(transcript_dict, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./libs/util_modelo_final.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./libs/util_modelo_final.py\n",
    "import os\n",
    "import shutil\n",
    "import util_fasta, util_caracteristicas\n",
    "from sklearn.externals.joblib import Parallel, delayed, dump, load\n",
    "import hashlib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, precision_recall_curve, average_precision_score, roc_curve, roc_auc_score\n",
    "import hashlib\n",
    "import util_fasta\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "class Tesis2():\n",
    "    def __init__(self, carpeta_base=\".\", n_jobs=-1, verbose=0, tuned_parameters=[{'svc__kernel': ['rbf'], 'svc__gamma': [1e-3], 'svc__C': [0.1,0.5,0.9,2]}], score = ['accuracy','precision','recall']):\n",
    "        self.carpeta_base = carpeta_base\n",
    "        self.n_jobs = n_jobs\n",
    "        self.verbose = verbose\n",
    "        self.tuned_parameters = tuned_parameters\n",
    "        self.score = score\n",
    "        self.carpeta_data_base = self.carpeta_base + \"/data\"\n",
    "        self.carpeta_fold_base = self.carpeta_base + \"/folds\"\n",
    "        self.carpeta_modelo_base = self.carpeta_base + \"/modelo_final\"\n",
    "        if not os.path.isdir(self.carpeta_base):\n",
    "            os.mkdir(self.carpeta_base)\n",
    "        self.diamond_db = \"./feature_engine/Diamond_BD/uniprot-viridiplantae-reviewed.dmnd\"\n",
    "        self.modelo_final_generado = False\n",
    "        self.modelo_referencial_generado = False\n",
    "            \n",
    "    def generar_modelo_final(self):\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"*************** Generando llaves ****************\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.generar_llaves_clases()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"***************** Armando folds *****************\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.armar_folds()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"***** Generando modelo cpat para cada fold ******\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.generar_cpats_de_folds()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"*** Ejecutando cpat y diamond sobre los folds ***\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.ejecutar_cpat_diamond_folds()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"************* Serializando features *************\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.generar_features_folds()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"************ Generando modelo final *************\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.entrenar_modelo_final()\n",
    "        self.modelo_final_generado = True\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"******** Limpiando archivos intermedios *********\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.limpiar_archivos_intermedios()\n",
    "        if (self.verbose > 1):\n",
    "            print(\"*************************************************\")\n",
    "            print(\"************* Mostrando resultados **************\")\n",
    "            print(\"*************************************************\")\n",
    "            self.mostrar_resultados()\n",
    "            \n",
    "    def generar_modelo_final_keras(self):\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"*************** Generando llaves ****************\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.generar_llaves_clases()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"***************** Armando folds *****************\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.armar_folds()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"***** Generando modelo cpat para cada fold ******\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.generar_cpats_de_folds()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"*** Ejecutando cpat y diamond sobre los folds ***\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.ejecutar_cpat_diamond_folds()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"************* Serializando features *************\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.generar_features_folds()\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"************ Generando modelo final *************\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.entrenar_modelo_final_keras()\n",
    "        self.modelo_final_generado = True\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"******** Limpiando archivos intermedios *********\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.limpiar_archivos_intermedios()\n",
    "        if (self.verbose > 1):\n",
    "            print(\"*************************************************\")\n",
    "            print(\"************* Mostrando resultados **************\")\n",
    "            print(\"*************************************************\")\n",
    "            self.mostrar_resultados()\n",
    "            \n",
    "    def generar_modelos_referenciales(self):\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        if (self.verbose > 1): print(\"******* Generando modelos referenciales *********\")\n",
    "        if (self.verbose > 1): print(\"*************************************************\")\n",
    "        self.entrenar_modelos_referenciales()\n",
    "        self.modelo_referencial_generado = True\n",
    "        if (self.modelo_final_generado and self.verbose > 1):\n",
    "            print(\"*************************************************\")\n",
    "            print(\"************* Mostrando resultados **************\")\n",
    "            print(\"*************************************************\")\n",
    "            self.mostrar_resultados_referencial_vs_final()\n",
    "        \n",
    "    def carpeta_data(self):\n",
    "        return self.carpeta_data_base\n",
    "\n",
    "    def carpeta_fold(self):\n",
    "        return self.carpeta_fold_base\n",
    "\n",
    "    def carpeta_modelo(self):\n",
    "        return self.carpeta_modelo_base\n",
    "    \n",
    "    def folder_clase(self, num_clase):\n",
    "        return self.carpeta_data() + \"/clase_\" + str(num_clase)\n",
    "\n",
    "    def archivo_clase(self, num_clase, tipo):\n",
    "        return self.folder_clase(num_clase) + \"/\" + tipo + \".fa\"\n",
    "\n",
    "    def obtener_num_clases(self):\n",
    "        num_clases = 0\n",
    "        if not os.path.isfile(self.carpeta_base + \"/num_clases.bin\"):\n",
    "            while os.path.isdir(self.folder_clase(num_clases + 1)):\n",
    "                num_clases = num_clases + 1\n",
    "            dump(num_clases, self.carpeta_base + \"/num_clases.bin\")\n",
    "        num_clases = load(self.carpeta_base + \"/num_clases.bin\")\n",
    "        return num_clases\n",
    "\n",
    "    def iterador_clases(self):\n",
    "        return range(1, self.obtener_num_clases() + 1)\n",
    "\n",
    "    def obtener_primera_secuencia(self, num_clase):\n",
    "        secuencias = util_fasta.leer_fasta(self.archivo_clase(num_clase, \"lncRNA\"), 1)\n",
    "        return list(secuencias.keys())[0]\n",
    "\n",
    "    def obtener_todas_las_secuencias(self):\n",
    "        return {num_clase : self.obtener_primera_secuencia(num_clase) for num_clase in self.iterador_clases()}\n",
    "\n",
    "    def generar_llaves_clases(self):\n",
    "        secuencias = self.obtener_todas_las_secuencias()\n",
    "        llaves = {num_clase : \"\" for num_clase in secuencias.keys()}\n",
    "        llaves[0] = \"\" #llave cero corresponde a todo el universo\n",
    "        for i_clase in self.iterador_clases():\n",
    "            llaves[0] += secuencias[i_clase]\n",
    "            for j_clase in self.iterador_clases():\n",
    "                if (i_clase != j_clase):\n",
    "                    llaves[j_clase] += secuencias[i_clase]\n",
    "        llaves[0] = hashlib.sha224(llaves[0].encode()).hexdigest()\n",
    "        for i_clase in self.iterador_clases():\n",
    "            llaves[i_clase] = hashlib.sha224(llaves[i_clase].encode()).hexdigest()\n",
    "        dump(llaves, self.carpeta_base + \"/llaves_clases.bin\")\n",
    "\n",
    "    def obtener_llaves_clases(self):\n",
    "        return load(self.carpeta_base + \"/llaves_clases.bin\")\n",
    "\n",
    "    def carpeta_fold_clase(self, llave):\n",
    "        return self.carpeta_fold() + \"/fold_clase_\" + str(llave)\n",
    "\n",
    "    def archivo_fold_clase(self, llave, tipoTrainTest, tipoRNA):\n",
    "        return self.carpeta_fold_clase(llave) + \"/\" + tipoTrainTest + \"/\" + tipoRNA + \".fa\"\n",
    "\n",
    "    def armar_fold_final(self, tipo):\n",
    "        llave = self.obtener_llaves_clases()[0]\n",
    "        with open(self.archivo_fold_clase(llave, \"train\", tipo), \"w+\") as outfile:\n",
    "            for num_clase in self.iterador_clases():\n",
    "                with open(self.archivo_clase(num_clase, tipo), \"r\") as infile:\n",
    "                    for inline in infile:\n",
    "                        outfile.write(inline)\n",
    "\n",
    "    def armar_fold_clase(self, num_clase):\n",
    "        llave = self.obtener_llaves_clases()[num_clase]\n",
    "        os.mkdir(self.carpeta_fold_clase(llave))\n",
    "        os.mkdir(self.carpeta_fold_clase(llave) + \"/train\")\n",
    "        for tipo in [\"lncRNA\", \"PCT\", \"CDS\"]:\n",
    "            with open(self.archivo_fold_clase(llave, \"train\", tipo), \"w+\") as outfile:\n",
    "                for j_num_clase in self.iterador_clases():\n",
    "                    if num_clase != j_num_clase:\n",
    "                        with open(self.archivo_clase(j_num_clase, tipo)) as infile:\n",
    "                            for inline in infile:\n",
    "                                outfile.write(inline)\n",
    "        os.mkdir(self.carpeta_fold_clase(llave) + \"/test\")\n",
    "        for tipo in [\"lncRNA\", \"PCT\"]:\n",
    "            with open(self.archivo_fold_clase(llave, \"test\", tipo), \"w+\") as outfile:\n",
    "                with open(self.archivo_clase(num_clase, tipo)) as infile:\n",
    "                    for inline in infile:\n",
    "                        outfile.write(inline)\n",
    "                    \n",
    "    def armar_folds(self):\n",
    "        if os.path.isdir(self.carpeta_fold()):\n",
    "            shutil.rmtree(self.carpeta_fold())\n",
    "        os.mkdir(self.carpeta_fold())\n",
    "        llave = self.obtener_llaves_clases()[0]\n",
    "        if not os.path.isdir(self.carpeta_fold_clase(llave)):\n",
    "            os.mkdir(self.carpeta_fold_clase(llave))\n",
    "        if not os.path.isdir(self.carpeta_fold_clase(llave) + \"/train\"):\n",
    "            os.mkdir(self.carpeta_fold_clase(llave) + \"/train\")\n",
    "\n",
    "        Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(delayed(wrapper_armar_fold_final)(self, tipo) for tipo in [\"lncRNA\", \"PCT\", \"CDS\"])\n",
    "        Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(delayed(wrapper_armar_fold_clase)(self, num_clase) for num_clase in self.iterador_clases())\n",
    "        \n",
    "    def carpeta_fold_cpat(self, llave):\n",
    "        return self.carpeta_fold_clase(llave) + \"/cpat\"\n",
    "\n",
    "    def generar_cpat_fold(self, num_clase):\n",
    "        llave = self.obtener_llaves_clases()[num_clase]\n",
    "        archivo_lncRNA = self.archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "        archivo_PCT = self.archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "        archivo_CDS = self.archivo_fold_clase(llave, \"train\", \"CDS\")\n",
    "        carpeta_cpat = self.carpeta_fold_cpat(llave)\n",
    "        if not os.path.isdir(carpeta_cpat):\n",
    "            os.mkdir(carpeta_cpat)\n",
    "        util_caracteristicas.generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat)\n",
    "\n",
    "    def generar_cpat_final(self):\n",
    "        llave = self.obtener_llaves_clases()[0]\n",
    "        archivo_lncRNA = self.archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "        archivo_PCT = self.archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "        archivo_CDS = self.archivo_fold_clase(llave, \"train\", \"CDS\")\n",
    "        carpeta_cpat = self.carpeta_fold_cpat(llave)\n",
    "        if not os.path.isdir(carpeta_cpat):\n",
    "            os.mkdir(carpeta_cpat)\n",
    "        util_caracteristicas.generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat)\n",
    "\n",
    "    def limpieza_archivos_CDS(self, num_clase):\n",
    "        llave = self.obtener_llaves_clases()[num_clase]\n",
    "        os.remove(self.archivo_fold_clase(llave, \"train\", \"CDS\"))\n",
    "        \n",
    "    def generar_cpats_de_folds(self):\n",
    "        self.generar_cpat_final()\n",
    "        Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(delayed(wrapper_generar_cpat_fold)(self, num_clase) for num_clase in self.iterador_clases())\n",
    "        self.limpieza_archivos_CDS(0)\n",
    "        Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(delayed(wrapper_limpieza_archivos_CDS)(self, num_clase) for num_clase in self.iterador_clases())\n",
    "    \n",
    "    def ejecutar_cpat_fold(self, num_clase):\n",
    "        llave = self.obtener_llaves_clases()[num_clase]\n",
    "        archivo_lncRNA = self.archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "        archivo_PCT = self.archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "        carpeta_cpat = self.carpeta_fold_cpat(llave)\n",
    "        util_caracteristicas.ejecutar_cpat(archivo_lncRNA, carpeta_cpat, archivo_lncRNA.replace(\".fa\", \".cpat\"))\n",
    "        os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "        os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".r\")\n",
    "        util_caracteristicas.ejecutar_cpat(archivo_PCT, carpeta_cpat, archivo_PCT.replace(\".fa\", \".cpat\"))\n",
    "        os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "        os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".r\")\n",
    "\n",
    "    def ejecutar_cpat_diamond_final(self):\n",
    "        llave = self.obtener_llaves_clases()[0]\n",
    "        archivo_lncRNA = self.archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "        archivo_PCT = self.archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "        diamond_db = self.diamond_db\n",
    "        carpeta_cpat = self.carpeta_fold_cpat(llave)\n",
    "        util_caracteristicas.ejecutar_diamond(archivo_lncRNA, diamond_db, archivo_lncRNA.replace(\".fa\", \".dmnd\"))\n",
    "        util_caracteristicas.ejecutar_diamond(archivo_PCT, diamond_db, archivo_PCT.replace(\".fa\", \".dmnd\"))\n",
    "        util_caracteristicas.ejecutar_cpat(archivo_lncRNA, carpeta_cpat, archivo_lncRNA.replace(\".fa\", \".cpat\"))\n",
    "        os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "        os.remove(archivo_lncRNA.replace(\".fa\", \".cpat\") + \".r\")\n",
    "        util_caracteristicas.ejecutar_cpat(archivo_PCT, carpeta_cpat, archivo_PCT.replace(\".fa\", \".cpat\"))\n",
    "        os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "        os.remove(archivo_PCT.replace(\".fa\", \".cpat\") + \".r\")\n",
    "        \n",
    "    def ejecutar_cpat_diamond_folds(self):\n",
    "        self.ejecutar_cpat_diamond_final()\n",
    "        Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(delayed(wrapper_ejecutar_cpat_fold)(self, num_clase) for num_clase in self.iterador_clases())\n",
    "        \n",
    "    def archivo_features_clase(self, llave, tipoTrainTest, tipoRNA):\n",
    "        return self.archivo_fold_clase(llave, tipoTrainTest, tipoRNA).replace(\".fa\", \".ft\")\n",
    "\n",
    "    def generar_features_fold(self, num_clase):\n",
    "        llave = self.obtener_llaves_clases()[num_clase]\n",
    "        features_base_lncRNA = self.archivo_features_clase(self.obtener_llaves_clases()[0], \"train\", \"lncRNA\")\n",
    "        features_base_PCT = self.archivo_features_clase(self.obtener_llaves_clases()[0], \"train\", \"PCT\")\n",
    "        for tipo in [\"train\", \"test\"]:\n",
    "            archivo_lncRNA = self.archivo_fold_clase(llave, tipo, \"lncRNA\")\n",
    "            archivo_PCT = self.archivo_fold_clase(llave, tipo, \"PCT\")\n",
    "            archivo_cpat_lncRNA = self.archivo_fold_clase(llave, \"train\", \"lncRNA\").replace(\".fa\", \".cpat\")\n",
    "            archivo_cpat_PCT = self.archivo_fold_clase(llave, \"train\", \"PCT\").replace(\".fa\", \".cpat\")\n",
    "            salida_lncRNA = self.archivo_features_clase(llave, tipo, \"lncRNA\")\n",
    "            salida_PCT = self.archivo_features_clase(llave, tipo, \"PCT\")\n",
    "            util_caracteristicas.generar_features(archivo_lncRNA, features_base_lncRNA, archivo_cpat_lncRNA, salida_lncRNA)\n",
    "            util_caracteristicas.generar_features(archivo_PCT, features_base_PCT, archivo_cpat_PCT, salida_PCT)\n",
    "\n",
    "    def generar_features_final(self):\n",
    "        llave = self.obtener_llaves_clases()[0]\n",
    "        archivo_lncRNA = self.archivo_fold_clase(llave, \"train\", \"lncRNA\")\n",
    "        archivo_PCT = self.archivo_fold_clase(llave, \"train\", \"PCT\")\n",
    "        salida_lncRNA = self.archivo_features_clase(llave, \"train\", \"lncRNA\")\n",
    "        salida_PCT = self.archivo_features_clase(llave, \"train\", \"PCT\")\n",
    "        util_caracteristicas.generar_features_base(archivo_lncRNA, archivo_lncRNA.replace(\".fa\", \".cpat\"), archivo_lncRNA.replace(\".fa\", \".dmnd\"), salida_lncRNA)\n",
    "        util_caracteristicas.generar_features_base(archivo_PCT, archivo_PCT.replace(\".fa\", \".cpat\"), archivo_PCT.replace(\".fa\", \".dmnd\"), salida_PCT)\n",
    "        \n",
    "    def generar_features_folds(self):\n",
    "        self.generar_features_final()\n",
    "        Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(delayed(wrapper_generar_features_fold)(self, num_clase) for num_clase in self.iterador_clases())\n",
    "        \n",
    "    def obtener_data_entrenamiento(self):\n",
    "        llave = self.obtener_llaves_clases()[0]\n",
    "        codigos_lncRNA = util_fasta.leer_fasta_list(self.archivo_fold_clase(llave, \"train\", \"lncRNA\"))\n",
    "        codigos_PCT = util_fasta.leer_fasta_list(self.archivo_fold_clase(llave, \"train\", \"PCT\"))\n",
    "\n",
    "        codigos_lncRNA = [(x[0],\"\") for x in codigos_lncRNA]\n",
    "        codigos_PCT = [(x[0],\"\") for x in codigos_PCT]\n",
    "        cantidad_transcritos = len(codigos_lncRNA)//self.obtener_num_clases()\n",
    "\n",
    "        y = ([1] * len(codigos_lncRNA)) + ([0] * len(codigos_PCT))\n",
    "        groups = list()\n",
    "        for _ in range(2):\n",
    "            for num_clase in self.iterador_clases():\n",
    "                groups += ([num_clase] * (cantidad_transcritos))\n",
    "        return codigos_lncRNA + codigos_PCT, y, groups, cantidad_transcritos\n",
    "        \n",
    "    def obtener_data_entrenamiento_keras(self):\n",
    "        llave = self.obtener_llaves_clases()[0]\n",
    "        codigos_lncRNA = util_fasta.leer_fasta_list(self.archivo_fold_clase(llave, \"train\", \"lncRNA\"))\n",
    "        codigos_PCT = util_fasta.leer_fasta_list(self.archivo_fold_clase(llave, \"train\", \"PCT\"))\n",
    "\n",
    "        codigos_lncRNA = [(x[0],\"\") for x in codigos_lncRNA]\n",
    "        codigos_PCT = [(x[0],\"\") for x in codigos_PCT]\n",
    "        cantidad_transcritos = len(codigos_lncRNA)//self.obtener_num_clases()\n",
    "\n",
    "        y = ([1] * len(codigos_lncRNA)) + ([0] * len(codigos_PCT))\n",
    "        groups = list()\n",
    "        for _ in range(2):\n",
    "            for num_clase in self.iterador_clases():\n",
    "                groups += ([num_clase] * (cantidad_transcritos))\n",
    "        x = codigos_lncRNA + codigos_PCT\n",
    "        \n",
    "        reserva_x = list()\n",
    "        reserva_y = list()\n",
    "        reserva_groups = list()\n",
    "        iremove = list()\n",
    "        num_transcritos = len(x)\n",
    "        num_transcritos_por_grupo = cantidad_transcritos\n",
    "        for i in range(num_transcritos//(num_transcritos_por_grupo*2)):\n",
    "            reserva_x.append(x[i * num_transcritos_por_grupo])\n",
    "            reserva_y.append(y[i * num_transcritos_por_grupo])\n",
    "            reserva_groups.append(groups[i * num_transcritos_por_grupo])\n",
    "            iremove.insert(0, i * num_transcritos_por_grupo)\n",
    "        for i in iremove:\n",
    "            del x[i]\n",
    "            del y[i]\n",
    "            del groups[i]\n",
    "        x, y, groups = shuffle(x, y, groups, random_state=7)\n",
    "        for i in range(num_transcritos//(num_transcritos_por_grupo*2)):\n",
    "            x.insert(i, reserva_x[i])\n",
    "            y.insert(i, reserva_y[i])\n",
    "            groups.insert(i, reserva_groups[i])\n",
    "            \n",
    "        return x, y, groups, cantidad_transcritos\n",
    "\n",
    "    def entrenar_modelo_final(self):\n",
    "        if os.path.isdir(self.carpeta_modelo()):\n",
    "            shutil.rmtree(self.carpeta_modelo())\n",
    "        os.mkdir(self.carpeta_modelo())\n",
    "        X_train, y_train, groups, cantidad_transcritos = self.obtener_data_entrenamiento()\n",
    "        svm_pipeline = Pipeline(steps=[('features', GeneradorFeatures(self, cantidad_transcritos, self.obtener_num_clases())), ('scaler', RobustScaler()), ('svc', SVC())])\n",
    "        logo = LeaveOneGroupOut()\n",
    "        clf = GridSearchCV(svm_pipeline, self.tuned_parameters, cv=logo, scoring=self.score, n_jobs=self.n_jobs, refit=\"accuracy\", return_train_score = True, verbose=self.verbose)\n",
    "        clf.fit(X_train, y_train, groups) #requerido por LeaveOneGroupOut\n",
    "        resultado = {\n",
    "            \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "            \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "            \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "        }\n",
    "        dump(resultado, self.carpeta_modelo() + \"/resultado.bin\")\n",
    "        dump(clf.best_params_, self.carpeta_modelo() + \"/params.bin\")\n",
    "        dump(clf.cv_results_, self.carpeta_modelo() + \"/cv_results.bin\")\n",
    "        dump(clf.best_estimator_, self.carpeta_modelo() + \"/modelo.plk\")\n",
    "\n",
    "    def entrenar_modelo_final_keras(self):\n",
    "        if os.path.isdir(self.carpeta_modelo()):\n",
    "            shutil.rmtree(self.carpeta_modelo())\n",
    "        os.mkdir(self.carpeta_modelo())\n",
    "        X_train, y_train, groups, cantidad_transcritos = self.obtener_data_entrenamiento_keras()\n",
    "        #X_train, y_train, groups = shuffle(X_train, y_train, groups, random_state=7)\n",
    "        keras_pipeline = Pipeline(steps=[('features', GeneradorFeaturesKeras(self, cantidad_transcritos, self.obtener_num_clases())), ('scaler', RobustScaler()), ('keras', KerasClassifier(build_fn=crear_modelo_keras, verbose=0))])\n",
    "        logo = LeaveOneGroupOut()\n",
    "        clf = GridSearchCV(keras_pipeline, self.tuned_parameters, cv=logo, scoring=self.score, n_jobs=self.n_jobs, refit=\"accuracy\", return_train_score = True, verbose=self.verbose)\n",
    "        clf.fit(X_train, y_train, groups) #requerido por LeaveOneGroupOut\n",
    "        resultado = {\n",
    "            \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "            \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "            \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "        }\n",
    "        dump(resultado, self.carpeta_modelo() + \"/resultado.bin\")\n",
    "        dump(clf.best_params_, self.carpeta_modelo() + \"/params.bin\")\n",
    "        dump(clf.cv_results_, self.carpeta_modelo() + \"/cv_results.bin\")\n",
    "        dump(clf.best_estimator_, self.carpeta_modelo() + \"/modelo.plk\")\n",
    "        \n",
    "    def limpieza_archivos_finales_fasta_ruta(self, llave):\n",
    "        shutil.rmtree(self.carpeta_fold_clase(llave))\n",
    "\n",
    "    def limpieza_archivos_finales_fasta(self, num_clase):\n",
    "        llave = self.obtener_llaves_clases()[num_clase]\n",
    "        if num_clase == 0:\n",
    "            shutil.rmtree(self.carpeta_fold_clase(llave) + \"/train\")\n",
    "        else:\n",
    "            self.limpieza_archivos_finales_fasta_ruta(llave)\n",
    "    \n",
    "    def limpiar_archivos_intermedios(self):\n",
    "        self.limpieza_archivos_finales_fasta(0)\n",
    "        Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(delayed(wrapper_limpieza_archivos_finales_fasta)(self, num_clase) for num_clase in self.iterador_clases())\n",
    "        self.features_pre_generados = False\n",
    "        \n",
    "    def mostrar_resultados(self):\n",
    "        if (not self.modelo_final_generado):\n",
    "            print(\"Debe generar el modelo final\")\n",
    "            return\n",
    "        display(load(self.carpeta_modelo() + \"/cv_results.bin\"))\n",
    "        display(load(self.carpeta_modelo() + \"/params.bin\"))\n",
    "        display(load(self.carpeta_modelo() + \"/resultado.bin\"))\n",
    "        if (self.modelo_referencial_generado):\n",
    "            self.mostrar_resultados_referencial_vs_final()\n",
    "        \n",
    "    def devolver_resultado(self):\n",
    "        return load(self.carpeta_modelo() + \"/resultado.bin\")\n",
    "        \n",
    "    def devolver_mejor_parametro(self):\n",
    "        return load(self.carpeta_modelo() + \"/params.bin\")\n",
    "        \n",
    "    def devolver_cv_results(self):\n",
    "        return load(self.carpeta_modelo() + \"/cv_results.bin\")\n",
    "        \n",
    "    def devolver_mejor_modelo(self):\n",
    "        return load(self.carpeta_modelo() + \"/modelo.plk\")\n",
    "        \n",
    "    def preparar_data_modelo_referencial(self, num_clase):\n",
    "        carpeta_base_referencial = self.carpeta_base + \"/modelos_referenciales/clase_\" + str(num_clase)\n",
    "        if not os.path.isdir(carpeta_base_referencial):\n",
    "            os.mkdir(carpeta_base_referencial)\n",
    "        if not os.path.isdir(carpeta_base_referencial + \"/data\"):\n",
    "            os.mkdir(carpeta_base_referencial + \"/data\")\n",
    "        clase_positiva = util_fasta.leer_fasta_list(self.archivo_clase(num_clase, \"lncRNA\"))\n",
    "        PCT = util_fasta.leer_fasta(self.archivo_clase(num_clase, \"PCT\"))\n",
    "        CDS = util_fasta.leer_fasta(self.archivo_clase(num_clase, \"CDS\"))\n",
    "        clase_negativa = list()\n",
    "        for k in PCT.keys():\n",
    "            clase_negativa.append((k, PCT[k], CDS[k]))\n",
    "        X = clase_positiva + clase_negativa\n",
    "        y = ([1] * len(clase_positiva)) + ([0] * len(clase_negativa))\n",
    "        skf = StratifiedKFold(n_splits=10)\n",
    "        isplit = 1\n",
    "        for _, test in skf.split(X, y):\n",
    "            split_lncRNA = list()\n",
    "            split_PCT = list()\n",
    "            split_CDS = list()\n",
    "            for itest in test:\n",
    "                if y[itest] == 1:\n",
    "                    split_lncRNA.append(X[itest])\n",
    "                else:\n",
    "                    split_PCT.append((X[itest][0], X[itest][1]))\n",
    "                    split_CDS.append((X[itest][0], X[itest][2]))\n",
    "            if not os.path.isdir(carpeta_base_referencial + \"/data/clase_\" + str(isplit)):\n",
    "                os.mkdir(carpeta_base_referencial + \"/data/clase_\" + str(isplit))\n",
    "            util_fasta.generar_fasta(split_lncRNA, carpeta_base_referencial + \"/data/clase_\" + str(isplit) + \"/lncRNA.fa\")\n",
    "            util_fasta.generar_fasta(split_PCT, carpeta_base_referencial + \"/data/clase_\" + str(isplit) + \"/PCT.fa\")\n",
    "            util_fasta.generar_fasta(split_CDS, carpeta_base_referencial + \"/data/clase_\" + str(isplit) + \"/CDS.fa\")\n",
    "            isplit += 1\n",
    "            \n",
    "    def instanciar_modelo_referencial(self, num_clase):\n",
    "        carpeta_base_referencial = self.carpeta_base + \"/modelos_referenciales/clase_\" + str(num_clase)\n",
    "        return Tesis2(carpeta_base=carpeta_base_referencial, n_jobs=self.n_jobs, verbose=0, tuned_parameters=self.tuned_parameters, score=self.score)\n",
    "        \n",
    "    def crear_modelo_referencial(self, num_clase):\n",
    "        carpeta_base_referencial = self.carpeta_base + \"/modelos_referenciales/clase_\" + str(num_clase)\n",
    "        self.preparar_data_modelo_referencial(num_clase)\n",
    "        tesis2 = self.instanciar_modelo_referencial(num_clase)\n",
    "        tesis2.generar_modelo_final()\n",
    "        shutil.rmtree(carpeta_base_referencial + \"/data\")\n",
    "    \n",
    "    def entrenar_modelos_referenciales(self):\n",
    "        if not os.path.isdir(self.carpeta_base + \"/modelos_referenciales\"):\n",
    "            os.mkdir(self.carpeta_base + \"/modelos_referenciales\")\n",
    "        Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(delayed(wrapper_crear_modelo_referencial)(self, num_clase) for num_clase in self.iterador_clases())\n",
    "        \n",
    "    def obtener_resultados_referencial_vs_final(self):\n",
    "        resultado_referencial = list()\n",
    "        resultado_final = list()\n",
    "        if (not self.modelo_final_generado) or (not self.modelo_referencial_generado):\n",
    "            print(\"Debe generar ambos modelos para obtener resultados comparativos\")\n",
    "            return resultado_referencial, resultado_final \n",
    "        parametros = self.devolver_mejor_parametro()\n",
    "        resultados = self.devolver_cv_results()\n",
    "        i_seleccionado = 0\n",
    "        i_iter = 0\n",
    "        for param in resultados[\"params\"]:\n",
    "            if parametros == param:\n",
    "                i_seleccionado = i_iter\n",
    "            i_iter += 1\n",
    "\n",
    "        for i in range(self.obtener_num_clases()):\n",
    "            resultado_referencial.append(self.instanciar_modelo_referencial(i+1).devolver_resultado()[\"accuracy\"])\n",
    "            resultado_final.append(resultados[\"split\" + str(i) + \"_test_accuracy\"][i_seleccionado])\n",
    "        return resultado_referencial, resultado_final\n",
    "        \n",
    "    def mostrar_resultados_referencial_vs_final(self):\n",
    "        if (not self.modelo_final_generado) or (not self.modelo_referencial_generado):\n",
    "            print(\"Debe generar ambos modelos para obtener resultados comparativos\")\n",
    "            return\n",
    "        resultado_referencial, resultado_final = self.obtener_resultados_referencial_vs_final()\n",
    "        for i in range(self.obtener_num_clases()):\n",
    "            print(\"***************\")\n",
    "            print(\"*** CLASE \" + str(i+1) + \" ***\")\n",
    "            print(\"***************\")\n",
    "\n",
    "            acc_mr = resultado_referencial[i]\n",
    "            acc_mf = resultado_final[i]\n",
    "\n",
    "            print(\"Accuracy modelo referencial: \" + '{:.1%}'.format(acc_mr))\n",
    "            print(\"Accuracy modelo final: \" + '{:.1%}'.format(acc_mf))\n",
    "            print(\"\")\n",
    "\n",
    "        print(\"********************\")\n",
    "        print(\"*** MODELO FINAL ***\")\n",
    "        print(\"********************\")  \n",
    "        print(\"Accuracy modelo final: \" + '{:.1%}'.format(self.devolver_resultado()[\"accuracy\"]))\n",
    "        print(\"\")\n",
    "        \n",
    "    def generar_predictor_final(self):\n",
    "        predictor = self.devolver_mejor_modelo()\n",
    "        llave_fold_final = self.obtener_llaves_clases()[0]\n",
    "        nuevo_generador_features = GeneradorFeaturesParaPredicciones(carpeta_base=self.carpeta_base, diamond_db=self.diamond_db, carpeta_cpat=self.carpeta_fold_cpat(llave_fold_final))\n",
    "        predictor.steps.pop(0)\n",
    "        predictor.steps.insert(0,['features', nuevo_generador_features])\n",
    "        dump(predictor, self.carpeta_modelo() + \"/modelo_final.plk\")\n",
    "        \n",
    "    def reportar_predicciones(self, archivo_lncRNA, archivo_PCT):\n",
    "        y_pred_lncRNA = self.realizar_predicciones(archivo_lncRNA)\n",
    "        probs_lncRNA = self.realizar_predicciones_proba(archivo_lncRNA, features_calculados=True)\n",
    "        y_pred_PCT = self.realizar_predicciones(archivo_PCT)\n",
    "        probs_PCT = self.realizar_predicciones_proba(archivo_PCT, features_calculados=True)\n",
    "        \n",
    "        y_true = ([1] * len(y_pred_lncRNA)) + ([0] * len(y_pred_PCT))\n",
    "        y_pred = np.concatenate((y_pred_lncRNA, y_pred_PCT))\n",
    "        \n",
    "        plt.figure(1)\n",
    "        probs = np.concatenate((probs_lncRNA[:,1], probs_PCT[:,1]))\n",
    "        precision, recall, _ = precision_recall_curve(y_true, probs)\n",
    "        average_precision = average_precision_score(y_true, probs)\n",
    "        plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "        plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "        \n",
    "        plt.figure(2)\n",
    "        fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "        roc_auc = roc_auc_score(y_true, probs)\n",
    "        plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')  # random predictions curve\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "        plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        \n",
    "        return classification_report(y_true, y_pred, target_names=[\"PCT\", \"lncRNA\"]), confusion_matrix(y_true, y_pred), precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "        \n",
    "    def reportar_predicciones_keras(self, archivo_lncRNA, archivo_PCT):\n",
    "        y_pred_lncRNA = self.realizar_predicciones(archivo_lncRNA)\n",
    "        probs_lncRNA = self.realizar_predicciones_proba_keras(archivo_lncRNA, features_calculados=True)\n",
    "        y_pred_PCT = self.realizar_predicciones(archivo_PCT)\n",
    "        probs_PCT = self.realizar_predicciones_proba_keras(archivo_PCT, features_calculados=True)\n",
    "        \n",
    "        y_true = ([1] * len(y_pred_lncRNA)) + ([0] * len(y_pred_PCT))\n",
    "        y_pred = np.concatenate((y_pred_lncRNA, y_pred_PCT))\n",
    "        \n",
    "        plt.figure(1)\n",
    "        probs = np.concatenate((probs_lncRNA[:,1], probs_PCT[:,1]))\n",
    "        precision, recall, _ = precision_recall_curve(y_true, probs)\n",
    "        average_precision = average_precision_score(y_true, probs)\n",
    "        plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "        plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "        \n",
    "        plt.figure(2)\n",
    "        fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "        roc_auc = roc_auc_score(y_true, probs)\n",
    "        plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')  # random predictions curve\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "        plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        \n",
    "        return classification_report(y_true, y_pred, target_names=[\"PCT\", \"lncRNA\"]), confusion_matrix(y_true, y_pred), precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "        \n",
    "    def realizar_predicciones(self, archivo_fasta, features_calculados=False):\n",
    "        predictor = load(self.carpeta_modelo() + \"/modelo_final.plk\")\n",
    "        X_test = util_fasta.leer_fasta_list(archivo_fasta)\n",
    "        predictor.set_params(features__features_calculados=features_calculados)\n",
    "        return predictor.predict(X_test)\n",
    "        \n",
    "    def realizar_predicciones_proba(self, archivo_fasta, features_calculados=False):\n",
    "        predictor = load(self.carpeta_modelo() + \"/modelo_final.plk\")\n",
    "        X_test = util_fasta.leer_fasta_list(archivo_fasta)\n",
    "        predictor.set_params(features__features_calculados=features_calculados)\n",
    "        return predictor.decision_function(X_test)\n",
    "        \n",
    "    def realizar_predicciones_proba_keras(self, archivo_fasta, features_calculados=False):\n",
    "        predictor = load(self.carpeta_modelo() + \"/modelo_final.plk\")\n",
    "        X_test = util_fasta.leer_fasta_list(archivo_fasta)\n",
    "        predictor.set_params(features__features_calculados=features_calculados)\n",
    "        return predictor.predict_proba(X_test)\n",
    "        \n",
    "#wrappers para ejecuciÃ³n en paralelo\n",
    "def wrapper_armar_fold_final(tesis2, tipo):\n",
    "    tesis2.armar_fold_final(tipo)\n",
    "        \n",
    "def wrapper_armar_fold_clase(tesis2, num_clase):\n",
    "    tesis2.armar_fold_clase(num_clase)\n",
    "    \n",
    "def wrapper_generar_cpat_fold(tesis2, num_clase):\n",
    "    tesis2.generar_cpat_fold(num_clase)\n",
    "    \n",
    "def wrapper_limpieza_archivos_CDS(tesis2, num_clase):\n",
    "    tesis2.limpieza_archivos_CDS(num_clase)\n",
    "    \n",
    "def wrapper_ejecutar_cpat_fold(tesis2, num_clase):\n",
    "    tesis2.ejecutar_cpat_fold(num_clase)\n",
    "    \n",
    "def wrapper_generar_features_fold(tesis2, num_clase):\n",
    "    tesis2.generar_features_fold(num_clase)\n",
    "    \n",
    "def wrapper_limpieza_archivos_finales_fasta(tesis2, num_clase):\n",
    "    tesis2.limpieza_archivos_finales_fasta(num_clase)\n",
    "\n",
    "def wrapper_crear_modelo_referencial(tesis2, num_clase):\n",
    "    tesis2.crear_modelo_referencial(num_clase)\n",
    "                                         \n",
    "def crear_modelo_keras(optimizer='adam', learn_rate=0.01, momentum=0, init_mode='uniform', activation='relu', activation2='softmax', dropout_rate=0.0, weight_constraint=1, neurons=10, hidden_layers=1, hidden_neurons=10):\n",
    "    #optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons, activation=activation, input_dim=10, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(units=hidden_neurons, activation=activation2, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer=init_mode))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "class GeneradorFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, tesis2=None, cantidad_transcritos=None, num_clases=None):\n",
    "        if cantidad_transcritos is None:\n",
    "            return\n",
    "        self.cantidad_transcritos = cantidad_transcritos\n",
    "        self.num_clases = num_clases\n",
    "        self.tesis2 = tesis2\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._llave_fold = self.obtener_llave_fold(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.obtener_features_pre_calculados(X)\n",
    "\n",
    "    def obtener_llave_fold(self, X):\n",
    "        cod_secuencias = \"\"\n",
    "        num_transcritos = len(X)\n",
    "        num_transcritos_por_grupo = self.cantidad_transcritos\n",
    "        for i in range(num_transcritos//(num_transcritos_por_grupo*2)):\n",
    "            cod_secuencias += X[i * num_transcritos_por_grupo][0]\n",
    "        llave = hashlib.sha224(cod_secuencias.encode()).hexdigest()\n",
    "        return llave\n",
    "\n",
    "    def obtener_features_pre_calculados(self, X):\n",
    "        llave = self._llave_fold\n",
    "        tipo = \"train\"\n",
    "        if os.path.isfile(self.tesis2.archivo_fold_clase(llave, \"test\", \"lncRNA\")):\n",
    "            secuencias = util_fasta.leer_fasta(self.tesis2.archivo_fold_clase(llave, \"test\", \"lncRNA\"), 1)\n",
    "            if list(secuencias.keys())[0] == X[0][0]:\n",
    "                tipo = \"test\"\n",
    "        features = list(load(self.tesis2.archivo_features_clase(llave, tipo, \"lncRNA\")).values())\n",
    "        features += list(load(self.tesis2.archivo_features_clase(llave, tipo, \"PCT\")).values())\n",
    "        return [list(x.values()) for x in features]\n",
    "    \n",
    "class GeneradorFeaturesKeras(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, tesis2=None, cantidad_transcritos=None, num_clases=None):\n",
    "        if cantidad_transcritos is None:\n",
    "            return\n",
    "        self.cantidad_transcritos = cantidad_transcritos\n",
    "        self.num_clases = num_clases\n",
    "        self.tesis2 = tesis2\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._llave_fold = self.obtener_llave_fold(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.obtener_features_pre_calculados(X)\n",
    "\n",
    "    def obtener_llave_fold(self, X):\n",
    "        cod_secuencias = \"\"\n",
    "        num_transcritos = len(X)\n",
    "        num_transcritos_por_grupo = self.cantidad_transcritos\n",
    "        for i in range(num_transcritos//(num_transcritos_por_grupo*2)):\n",
    "            cod_secuencias += X[i][0]\n",
    "        llave = hashlib.sha224(cod_secuencias.encode()).hexdigest()\n",
    "        return llave\n",
    "\n",
    "    def obtener_features_pre_calculados(self, X):\n",
    "        llave = self._llave_fold\n",
    "        tipo = \"train\"\n",
    "        if os.path.isfile(self.tesis2.archivo_fold_clase(llave, \"test\", \"lncRNA\")):\n",
    "            secuencias = util_fasta.leer_fasta(self.tesis2.archivo_fold_clase(llave, \"test\", \"lncRNA\"), 1)\n",
    "            if list(secuencias.keys())[0] == X[0][0]:\n",
    "                tipo = \"test\"\n",
    "        features = {**load(self.tesis2.archivo_features_clase(llave, tipo, \"lncRNA\")), **load(self.tesis2.archivo_features_clase(llave, tipo, \"PCT\"))}\n",
    "        return [list(features[x[0]].values()) for x in X]\n",
    "\n",
    "class GeneradorFeaturesParaPredicciones(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, carpeta_base=None, diamond_db=None, carpeta_cpat=None, features_calculados=False):\n",
    "        if carpeta_base is None:\n",
    "            return\n",
    "        self.carpeta_base = carpeta_base\n",
    "        self.diamond_db = diamond_db\n",
    "        self.carpeta_cpat = carpeta_cpat\n",
    "        self.features_calculados = features_calculados\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        raise Exception('Este modelo no admite fit')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        carpeta_transform = self.carpeta_base + \"/transform\"\n",
    "        if not os.path.isdir(carpeta_transform):\n",
    "            os.mkdir(carpeta_transform)\n",
    "        archivo_fasta = carpeta_transform + \"/secuencias.fa\"\n",
    "        if (not self.features_calculados):\n",
    "            self.generar_archivos_fasta(archivo_fasta, X)\n",
    "            self.ejecutar_diamond_cpat(archivo_fasta)\n",
    "            self.generar_features(archivo_fasta)\n",
    "        return self.obtener_features_pre_calculados(archivo_fasta)\n",
    "                          \n",
    "    def generar_archivos_fasta(self, archivo_fasta, X):\n",
    "        util_fasta.generar_fasta(X, archivo_fasta)\n",
    "    \n",
    "    def ejecutar_diamond_cpat(self, archivo_fasta):\n",
    "        diamond_db = self.diamond_db\n",
    "        carpeta_cpat = self.carpeta_cpat\n",
    "        util_caracteristicas.ejecutar_diamond(archivo_fasta, diamond_db, archivo_fasta.replace(\".fa\", \".dmnd\"))\n",
    "        util_caracteristicas.ejecutar_cpat(archivo_fasta, carpeta_cpat, archivo_fasta.replace(\".fa\", \".cpat\"))\n",
    "        os.remove(archivo_fasta.replace(\".fa\", \".cpat\") + \".dat\")\n",
    "        os.remove(archivo_fasta.replace(\".fa\", \".cpat\") + \".r\")\n",
    "        \n",
    "    def generar_features(self, archivo_fasta):\n",
    "        util_caracteristicas.generar_features_base(archivo_fasta, archivo_fasta.replace(\".fa\", \".cpat\"), archivo_fasta.replace(\".fa\", \".dmnd\"), archivo_fasta.replace(\".fa\", \".ft\"))\n",
    "\n",
    "    def obtener_features_pre_calculados(self, archivo_fasta):\n",
    "        features = list(load(archivo_fasta.replace(\".fa\", \".ft\")).values())\n",
    "        return [list(x.values()) for x in features]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
