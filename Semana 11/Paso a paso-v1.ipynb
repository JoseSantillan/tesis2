{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_especies = 3\n",
    "cantidad_transcritos = 400\n",
    "carpeta_data = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generaci√≥n de archivos fasta para las 30 especies\n",
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_bd, util_fasta\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.externals.joblib import Parallel, delayed, dump\n",
    "\n",
    "def obtener_especies():\n",
    "    query = \"SELECT * FROM (SELECT CONVERT(@row_number:=@row_number + 1, UNSIGNED) AS orden, m.id_especie, m.especie FROM especies_seleccionadas s JOIN maestra_especies m ON s.especie = m.especie, (SELECT @row_number:=0) AS rn ORDER BY m.id_especie) a ORDER BY 1 LIMIT \" + str(cantidad_especies)\n",
    "    return util_bd.resultados_query(query)\n",
    "        \n",
    "def generar_fasta_especie( row_especie):\n",
    "    os.mkdir(carpeta_data + \"/clase_\" + str(row_especie[0]))\n",
    "    # lncRNA\n",
    "    query = \"SELECT cod_secuencia, secuencia FROM secuencias WHERE flg_pct = 0 AND flg_seleccionado = 1 AND id_especie = \" + str(row_especie[1]) + \" ORDER BY cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data + \"/clase_\" + str(row_especie[0]) + \"/lncRNA.fa\")\n",
    "    # PCT\n",
    "    query = \"SELECT cod_secuencia, secuencia FROM secuencias WHERE flg_pct = 1 AND flg_seleccionado = 1 AND id_especie = \" + str(row_especie[1]) + \" ORDER BY cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data + \"/clase_\" + str(row_especie[0]) + \"/PCT.fa\")\n",
    "    # CDS\n",
    "    query = \"SELECT f.cod_secuencia, cds.coding FROM secuencias_CDS cds JOIN secuencias_features f ON cds.id_especie = f.id_especie AND cds.cod_secuencia = f.cod_secuencia WHERE f.flg_pct = 1 AND f.flg_seleccionado = 1 AND f.id_especie = \" + str(row_especie[1]) + \" ORDER BY f.cod_secuencia LIMIT \" + str(cantidad_transcritos)\n",
    "    secuencias = util_bd.resultados_query(query)\n",
    "    util_fasta.generar_fasta(secuencias, carpeta_data + \"/clase_\" + str(row_especie[0]) + \"/CDS.fa\")\n",
    "\n",
    "if os.path.isdir(carpeta_data):\n",
    "    shutil.rmtree(carpeta_data)\n",
    "os.mkdir(carpeta_data)\n",
    "\n",
    "%time dump(obtener_especies(), carpeta_data + \"/info_clases.bin\")\n",
    "%time Parallel(n_jobs=4, verbose=0)(delayed(generar_fasta_especie)(row_especie) for row_especie in obtener_especies())\n",
    "\n",
    "print(\"Proceso finalizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c anaconda tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c anaconda cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./libs')\n",
    "import util_caracteristicas\n",
    "from numpy import array\n",
    "\n",
    "carpeta_features = \"./features\"\n",
    "if os.path.isdir(carpeta_features):\n",
    "    shutil.rmtree(carpeta_features)\n",
    "os.mkdir(carpeta_features)\n",
    "os.mkdir(carpeta_features + \"/cpat\")\n",
    "os.mkdir(carpeta_features + \"/diamond\")\n",
    "\n",
    "tipo = \"train\"\n",
    "archivo_lncRNA = carpeta_data + \"/clase_1/lncRNA.fa\"\n",
    "archivo_PCT = carpeta_data + \"/clase_1/PCT.fa\"\n",
    "archivo_CDS = carpeta_data + \"/clase_1/CDS.fa\"\n",
    "carpeta_cpat = carpeta_features + \"/cpat\"\n",
    "util_caracteristicas.generar_modelo_CPAT(archivo_lncRNA, archivo_PCT, archivo_CDS, carpeta_cpat)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "diamond_db = \"./feature_engine/Diamond_BD/uniprot-viridiplantae-reviewed.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/diamond/\" + tipo + \"_lncRNA.dmnd\"\n",
    "util_caracteristicas.ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_salida = carpeta_features + \"/diamond/\" + tipo + \"_PCT.dmnd\"\n",
    "util_caracteristicas.ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "archivo_salida = carpeta_features + \"/cpat/\" + tipo + \"_lncRNA.cpat\"\n",
    "util_caracteristicas.ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_salida = carpeta_features + \"/cpat/\" + tipo + \"_PCT.cpat\"\n",
    "util_caracteristicas.ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "archivo_cpat = carpeta_features + \"/cpat/\" + tipo + \"_lncRNA.cpat\"\n",
    "archivo_diamond = carpeta_features + \"/diamond/\" + tipo + \"_lncRNA.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/\" + tipo + \"_lncRNA.ft\"\n",
    "util_caracteristicas.generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_cpat = carpeta_features + \"/cpat/\" + tipo + \"_PCT.cpat\"\n",
    "archivo_diamond = carpeta_features + \"/diamond/\" + tipo + \"_PCT.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/\" + tipo + \"_PCT.ft\"\n",
    "util_caracteristicas.generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida)\n",
    "\n",
    "tipo = \"test\"\n",
    "archivo_lncRNA = carpeta_data + \"/clase_2/lncRNA.fa\"\n",
    "archivo_PCT = carpeta_data + \"/clase_2/PCT.fa\"\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "diamond_db = \"./feature_engine/Diamond_BD/uniprot-viridiplantae-reviewed.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/diamond/\" + tipo + \"_lncRNA.dmnd\"\n",
    "util_caracteristicas.ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_salida = carpeta_features + \"/diamond/\" + tipo + \"_PCT.dmnd\"\n",
    "util_caracteristicas.ejecutar_diamond(archivo_entrada, diamond_db, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "archivo_salida = carpeta_features + \"/cpat/\" + tipo + \"_lncRNA.cpat\"\n",
    "util_caracteristicas.ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_salida = carpeta_features + \"/cpat/\" + tipo + \"_PCT.cpat\"\n",
    "util_caracteristicas.ejecutar_cpat(archivo_entrada, carpeta_cpat, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_lncRNA\n",
    "archivo_cpat = carpeta_features + \"/cpat/\" + tipo + \"_lncRNA.cpat\"\n",
    "archivo_diamond = carpeta_features + \"/diamond/\" + tipo + \"_lncRNA.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/\" + tipo + \"_lncRNA.ft\"\n",
    "util_caracteristicas.generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida)\n",
    "\n",
    "archivo_entrada = archivo_PCT\n",
    "archivo_cpat = carpeta_features + \"/cpat/\" + tipo + \"_PCT.cpat\"\n",
    "archivo_diamond = carpeta_features + \"/diamond/\" + tipo + \"_PCT.dmnd\"\n",
    "archivo_salida = carpeta_features + \"/\" + tipo + \"_PCT.ft\"\n",
    "util_caracteristicas.generar_features_base(archivo_entrada, archivo_cpat, archivo_diamond, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import load\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "features_train_lncRNA = load(carpeta_features + \"/train_lncRNA.ft\")\n",
    "features_train_PCT = load(carpeta_features + \"/train_PCT.ft\")\n",
    "features_test_lncRNA = load(carpeta_features + \"/test_lncRNA.ft\")\n",
    "features_test_PCT = load(carpeta_features + \"/test_PCT.ft\")\n",
    "\n",
    "features_train = [list(x.values()) for x in list(features_train_lncRNA.values()) + list(features_train_PCT.values())]\n",
    "features_test = [list(x.values()) for x in list(features_test_lncRNA.values()) + list(features_test_PCT.values())]\n",
    "        \n",
    "x_train = np.array(features_train)\n",
    "y_train = np.array(([1] * len(features_train_lncRNA)) + ([0] * len(features_train_PCT)))\n",
    "x_test = np.array(features_test)\n",
    "y_test = np.array(([1] * len(features_test_lncRNA)) + ([0] * len(features_test_PCT)))\n",
    "\n",
    "x_train = RobustScaler().fit_transform(x_train)\n",
    "x_test = RobustScaler().fit_transform(x_test)\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "#sess = tf.Session(config=config) \n",
    "#keras.backend.set_session(sess)\n",
    "\n",
    "def create_model(optimizer='adam', learn_rate=0.01, momentum=0, init_mode='uniform', activation='relu', activation2='softmax', dropout_rate=0.0, weight_constraint=1, neurons=10):\n",
    "    #optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=10, activation=activation, input_dim=10, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=neurons, activation=activation2, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer=init_mode))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "tuned_parameters = [{'batch_size': [2**5], 'epochs': [2**10], 'optimizer': ['Adam'], 'learn_rate': [0.01], 'momentum': [0], 'init_mode': ['uniform'], 'activation': ['relu'], 'activation': ['softmax'], 'dropout_rate': [0.0], 'weight_constraint': [1], 'neurons': [10]}]\n",
    "\n",
    "clf = GridSearchCV(model, tuned_parameters, cv=3, scoring=['accuracy','precision','recall'], n_jobs=1, refit=\"accuracy\", return_train_score = True, verbose=0)\n",
    "%time clf.fit(x_train, y_train)\n",
    "resultado = {\n",
    "    \"accuracy\" : clf.cv_results_['mean_test_accuracy'][clf.best_index_],\n",
    "    \"precision\" : clf.cv_results_['mean_test_precision'][clf.best_index_],\n",
    "    \"recall\" : clf.cv_results_['mean_test_recall'][clf.best_index_]\n",
    "}\n",
    "print(resultado)\n",
    "print(\"Best: %f using %s\" % (clf.best_score_, clf.best_params_))\n",
    "\n",
    "#clf = model\n",
    "#clf.fit(x_train, y_train)\n",
    "\n",
    "#history = model.fit(x_train, y_train, verbose=0)\n",
    "#plt.plot(history.history['loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, precision_recall_curve, average_precision_score\n",
    "\n",
    "y_true = clf.predict(x_test)\n",
    "print(confusion_matrix(y_true, y_test))\n",
    "print(classification_report(y_true, y_test, target_names=[\"lncRNA\", \"PCT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "predicted = clf.predict_proba(x_test)\n",
    "probs = predicted[:,1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "average_precision = average_precision_score(y_test, probs)\n",
    "plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fca038eefff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_available_gpus\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n\u001b[1;32m    185\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "    \n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.list_devices())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
